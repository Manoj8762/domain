{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "lR3S4qqmlbG2",
        "outputId": "fb620862-b8a3-49c8-81d9-f10c322f1622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-78220620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dga_version5.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# must have \"domain\" column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"domain\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0mfeat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-78220620.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(domain)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Char_Freq_Deviation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KL_divergence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Compression_ratio\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-78220620.py\u001b[0m in \u001b[0;36mkl_divergence\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBENIGN_DIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36maxis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypotest_fun_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_entropy.py\u001b[0m in \u001b[0;36mentropy\u001b[0;34m(pk, qk, base, axis)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# don't ignore any axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0msum_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36m_broadcast_arrays\u001b[0;34m(arrays, axis, xp)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mnew_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36m_broadcast_shapes\u001b[0;34m(shapes, axis)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# above, the arrays must not be broadcastable after all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shapes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_shapes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Array shapes are incompatible for broadcasting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_any_dispatcher\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m def _any_dispatcher(a, axis=None, out=None, keepdims=None, *,\n\u001b[0m\u001b[1;32m   2396\u001b[0m                     where=np._NoValue):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3572\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3574\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# dga_feature_extractor.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import zlib\n",
        "import gzip\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "from difflib import SequenceMatcher\n",
        "from scipy.stats import entropy, kurtosis\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Download dictionary\n",
        "download('words')\n",
        "english_words = set(w.lower() for w in words.words())\n",
        "\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(string.ascii_lowercase) - VOWELS\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "\n",
        "# Example benign distribution (uniform)\n",
        "BENIGN_DIST = np.ones(26) / 26\n",
        "\n",
        "def shannon_entropy(s):\n",
        "    p, _ = np.histogram(list(s), bins=range(257), density=True)\n",
        "    p = p[p > 0]\n",
        "    return -np.sum(p * np.log2(p))\n",
        "\n",
        "def normalized_entropy(s):\n",
        "    if not s: return 0\n",
        "    return shannon_entropy(s) / math.log2(len(set(s)) + 1)\n",
        "\n",
        "def compress_ratio(s):\n",
        "    if not s: return 0\n",
        "    return len(zlib.compress(s.encode())) / max(1, len(s))\n",
        "\n",
        "def dict_word_features(domain):\n",
        "    matches = [w for w in english_words if w in domain]\n",
        "    longest = max((len(w) for w in matches), default=0)\n",
        "    return len(matches), longest, longest / max(1,len(domain))\n",
        "\n",
        "def sliding_dict_ratio(domain, window=4):\n",
        "    n = len(domain)\n",
        "    if n < window: return 0\n",
        "    matches = 0\n",
        "    for i in range(n - window + 1):\n",
        "        if domain[i:i+window] in english_words:\n",
        "            matches += 1\n",
        "    return matches / (n - window + 1)\n",
        "\n",
        "def vowel_consonant_alt(domain):\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    count = 0\n",
        "    for i in range(1, len(domain)):\n",
        "        if (domain[i] in VOWELS and domain[i-1] in CONSONANTS) or (domain[i] in CONSONANTS and domain[i-1] in VOWELS):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "def char_gini(s):\n",
        "    counts = Counter(s)\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    gini = 1 - sum((c/N)**2 for c in counts.values())\n",
        "    return gini\n",
        "\n",
        "def kl_divergence(s):\n",
        "    counts = Counter([c for c in s if c.isalpha()])\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    dist = np.array([counts.get(chr(97+i),0)/N for i in range(26)])\n",
        "    return entropy(dist, BENIGN_DIST)\n",
        "\n",
        "def markov_chain_likelihood(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    transitions = {}\n",
        "    for i in range(len(domain)-1):\n",
        "        pair = (domain[i], domain[i+1])\n",
        "        transitions[pair] = transitions.get(pair, 0) + 1\n",
        "    total = sum(transitions.values())\n",
        "    return sum(math.log((c/total)+1e-6) for c in transitions.values())\n",
        "\n",
        "def autocorrelation_score(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    values = [ord(c) for c in domain]\n",
        "    mean = np.mean(values)\n",
        "    var = np.var(values)\n",
        "    corr = sum((values[i]-mean)*(values[i+1]-mean) for i in range(len(values)-1)) / (var*(len(values)-1)+1e-6)\n",
        "    return corr\n",
        "\n",
        "def hyphen_word_match_ratio(domain):\n",
        "    \"\"\"Compute ratio of hyphen-separated parts that are valid dictionary words.\"\"\"\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts:\n",
        "        return 0.0\n",
        "    dict_matches = sum(1 for p in parts if p in english_words)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "# === Extra Feature Functions ===\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    \"\"\"Rényi entropy of order alpha (default α=2).\"\"\"\n",
        "    if not s:\n",
        "        return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs * np.log2(probs))  # Shannon\n",
        "    return 1 / (1 - alpha) * np.log2(np.sum(probs ** alpha))\n",
        "\n",
        "# Load top domains (free list like Tranco or Cisco Umbrella top domains)\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        popular_domains = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    popular_domains = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]  # fallback demo list\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    \"\"\"Compute minimum normalized Levenshtein distance to topN popular domains.\"\"\"\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in popular_domains[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio  # 0 = identical, 1 = very different\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "# Keyboard adjacency mapping\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q': \"was\", 'w': \"qase\", 'e': \"wsdr\", 'r': \"edft\", 't': \"rfgy\",\n",
        "    'y': \"tghu\", 'u': \"yhj\", 'i': \"ujk\", 'o': \"ikl\", 'p': \"ol\",\n",
        "    'a': \"qwsz\", 's': \"qwedxza\", 'd': \"erfcxs\", 'f': \"rtgvcd\", 'g': \"tyhbvf\",\n",
        "    'h': \"yujnbg\", 'j': \"uikmnh\", 'k': \"iolmj\", 'l': \"opk\",\n",
        "    'z': \"asx\", 'x': \"zsdc\", 'c': \"xdfv\", 'v': \"cfgb\", 'b': \"vghn\",\n",
        "    'n': \"bhjm\", 'm': \"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    \"\"\"Average keyboard adjacency match score between consecutive characters.\"\"\"\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    if len(domain) < 2:\n",
        "        return 0\n",
        "    score = 0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i], \"\"):\n",
        "            score += 1\n",
        "    return score / (len(domain)-1)\n",
        "\n",
        "# === Updated extract_features ===\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str):\n",
        "        domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    name, _, tld = domain.rpartition(\".\")\n",
        "    if not name:\n",
        "        name = domain\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"Kolmogorov_Complexity\",\"Renyi_Entropy\",\"Min_Levenshtein_to_Popular\",\"Keyboard_Distance_Score\",\"Sliding_Word_Ratio\"\n",
        "\n",
        "    feats = {}\n",
        "\n",
        "\n",
        "\n",
        "    feats[\"Length\"] = len(domain)\n",
        "    feats[\"Consonant_Count\"] = sum(c in CONSONANTS for c in domain)\n",
        "    feats[\"Unique_Chars\"] = len(set(domain))\n",
        "    feats[\"Max_Cons_Cluster\"] = max((len(m.group()) for m in re.finditer(r'[bcdfghjklmnpqrstvwxyz]+', domain)), default=0)\n",
        "\n",
        "    # Info-theoretic\n",
        "    feats[\"Dist_STD\"] = np.std([domain.count(c) for c in set(domain)])\n",
        "    feats[\"Char_Gini\"] = char_gini(domain)\n",
        "    feats[\"Char_Freq_Deviation\"] = np.std(list(Counter(domain).values()))\n",
        "    feats[\"KL_divergence\"] = kl_divergence(domain)\n",
        "    feats[\"Compression_ratio\"] = compress_ratio(domain)\n",
        "\n",
        "    # Pronounceability\n",
        "    feats[\"Pronounceability\"] = sum(c in VOWELS for c in domain) / (sum(c in CONSONANTS for c in domain) + 1)\n",
        "\n",
        "    # N-gram / LM\n",
        "    feats[\"Bigram_Score\"] = sum(1 for i in range(len(domain) - 1) if domain[i].isalpha() and domain[i + 1].isalpha())\n",
        "    feats[\"Trigram_Score\"] = sum(1 for i in range(len(domain) - 2) if domain[i].isalpha() and domain[i + 2].isalpha())\n",
        "    feats[\"Markov_Chain_Likelihood\"] = markov_chain_likelihood(domain)\n",
        "    feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    feats[\"Ngram_LM_Perplexity\"] = math.exp(-markov_chain_likelihood(domain) / max(1, len(domain)))\n",
        "\n",
        "    # Structural/pattern\n",
        "    feats[\"Unique_Char_Ratio\"] = len(set(domain)) / max(1, len(domain))\n",
        "    feats[\"Norm_Char_Freq_Var\"] = np.std(list(Counter(domain).values())) / max(1, len(domain))\n",
        "\n",
        "\n",
        "\n",
        "    feats[\"Kolmogorov_Complexity\"] = compress_ratio(domain)\n",
        "\n",
        "   # === Advanced Features Added ===\n",
        "    feats[\"Renyi_Entropy\"] = renyi_entropy(domain, alpha=2)\n",
        "    feats[\"Min_Levenshtein_to_Popular\"] = min_levenshtein_to_popular(domain)\n",
        "    feats[\"Keyboard_Distance_Score\"] = keyboard_distance_score(domain)\n",
        "    feats[\"Sliding_Word_Ratio\"] = sliding_dict_ratio(domain)\n",
        "\n",
        "    #feats[\"Max_Repeated_Char_Run\"] = max( (len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##feats[\"Digit_Count\"] = sum(c.isdigit() for c in domain)\n",
        "    ##feats[\"Digit_Ratio\"] = feats[\"Digit_Count\"]/max(1,len(domain))\n",
        "    ##feats[\"Max_Consec_Digits\"] = max((len(m.group()) for m in re.finditer(r'\\d+', domain)), default=0)\n",
        "    ##feats[\"Vowel_Count\"] = sum(c in VOWELS for c in domain)\n",
        "    ##feats[\"Has_Hyphen\"] = \"-\" in domain\n",
        "    ##feats[\"Hyphen_Placement_Score\"] = 1 if domain.startswith(\"-\") or domain.endswith(\"-\") else 0\n",
        "    ##feats[\"Hyphen_Word_Match_Ratio\"] = hyphen_word_match_ratio(domain)\n",
        "    ##feats[\"Subdomain_Depth\"] = domain.count(\".\")\n",
        "    ##feats[\"Entropy\"] = shannon_entropy(domain)\n",
        "    #feats[\"Normalized_Entropy\"] = normalized_entropy(domain)\n",
        "    ##feats[\"Vowel_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c in VOWELS]))\n",
        "    ##feats[\"Consonant_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c not in VOWELS and c.isalpha()]))\n",
        "    #dwc, lwl, lwr = dict_word_features(domain)\n",
        "    #feats[\"Dict_Word_Count\"] = dwc\n",
        "    #feats[\"Longest_Word_Len\"] = lwl\n",
        "    #feats[\"Longest_Word_Ratio\"] = lwr\n",
        "    #feats[\"Word_Match_Ratio\"] = dwc/max(1,len(domain.split(\".\")))\n",
        "    #feats[\"Sliding_Word_Ratio\"] = sliding_dict_ratio(domain)\n",
        "    ##feats[\"Vowel_Consonant_Alt\"] = vowel_consonant_alt(domain)\n",
        "    #feats[\"Lexical_Complexity\"] = shannon_entropy(domain)*len(set(domain))/max(1,len(domain))\n",
        "    #feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    #feats[\"TLD_Common\"] = 1 if f\".{tld}\" in POPULAR_TLDS else 0\n",
        "    ##feats[\"TLD_Bad_Score\"] = 1 if f\".{tld}\" in BAD_TLDS else 0\n",
        "    ##feats[\"Popular_Domain\"] = 0  # needs Alexa dataset\n",
        "    ##feats[\"Alexa_popularity_bucket\"] = -1\n",
        "    #feats[\"Repeat_Chars\"] = max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "    ##feats[\"Max_Repeated_Char_Run\"] = feats[\"Repeat_Chars\"]\n",
        "    ##feats[\"Digit_Letter_Alt_Count\"] = sum((domain[i].isdigit() != domain[i+1].isdigit()) for i in range(len(domain)-1))\n",
        "    #feats[\"Palindromic_Substring_Ratio\"] = sum(domain[i:j]==domain[i:j][::-1] for i in range(len(domain)) for j in range(i+2,len(domain)+1))/max(1,len(domain))\n",
        "    ##feats[\"First_Last_Char_Type\"] = int(domain[0].isalpha()) + int(domain[-1].isalpha())\n",
        "    ##feats[\"Shannon_Window_Entropy\"] = np.mean([shannon_entropy(domain[i:i+4]) for i in range(len(domain)-3)]) if len(domain)>=4 else  shannon_entropy(domain)\n",
        "    ##feats[\"Markov_Cross_Entropy\"] = shannon_entropy(domain) -  markov_chain_likelihood(domain)\n",
        "    ##feats[\"Permutation_Entropy\"] = shannon_entropy(domain)/max(1,math.log2(len(domain)))\n",
        "    #feats[\"RunLength_Entropy\"] = shannon_entropy(\"\".join([str(len(m.group())) for m in re.finditer(r'(.)\\1*', domain)]))\n",
        "    #feats[\"Dict_Word_Coverage\"] = dwc/max(1,len(domain))\n",
        "    #feats[\"Longest_Word_Suffix\"] = max((len(w) for w in english_words if domain.endswith(w)), default=0)\n",
        "    #feats[\"Word_Boundary_Count\"] = domain.count(\"-\")\n",
        "    #feats[\"Syllable_Count\"] = sum(domain.count(v) for v in VOWELS)\n",
        "    #feats[\"TLD_Length\"] = len(tld)\n",
        "    #feats[\"TLD_Rarity_Score\"] = 0 if f\".{tld}\" in POPULAR_TLDS else 1\n",
        "    #feats[\"Autocorrelation_Score\"] = autocorrelation_score(domain)\n",
        "    #feats[\"Hurst_Exponent\"] = 0.5  # placeholder\n",
        "\n",
        "    return feats\n",
        "\n",
        "# === Run on a dataset ===\n",
        "df = pd.read_csv(\"dga_version5.csv\")  # must have \"domain\" column\n",
        "features = df[\"domain\"].apply(extract_features)\n",
        "feat_df = pd.DataFrame(list(features))\n",
        "out = pd.concat([df, feat_df], axis=1)\n",
        "out.to_csv(\"dga_18_version1.csv\", index=False)\n",
        "print(\"✅ Features saved to domains_with_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "kFwWhMzJDunx",
        "outputId": "a3732452-c128-445c-be98-35e2773fcd50"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-13fba12f-52dd-4848-92ce-37bd85cd5a50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Length</th>\n",
              "      <th>Consonant_Count</th>\n",
              "      <th>Unique_Chars</th>\n",
              "      <th>Max_Cons_Cluster</th>\n",
              "      <th>Dist_STD</th>\n",
              "      <th>Char_Gini</th>\n",
              "      <th>Char_Freq_Deviation</th>\n",
              "      <th>KL_divergence</th>\n",
              "      <th>Compression_ratio</th>\n",
              "      <th>...</th>\n",
              "      <th>Markov_Chain_Likelihood</th>\n",
              "      <th>Bigram_Likelihood</th>\n",
              "      <th>Ngram_LM_Perplexity</th>\n",
              "      <th>Unique_Char_Ratio</th>\n",
              "      <th>Norm_Char_Freq_Var</th>\n",
              "      <th>Kolmogorov_Complexity</th>\n",
              "      <th>Renyi_Entropy</th>\n",
              "      <th>Min_Levenshtein_to_Popular</th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "      <th>Sliding_Word_Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>694173.0</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.0</td>\n",
              "      <td>19.226092</td>\n",
              "      <td>12.200742</td>\n",
              "      <td>12.481366</td>\n",
              "      <td>4.576519</td>\n",
              "      <td>0.712628</td>\n",
              "      <td>0.897836</td>\n",
              "      <td>0.712628</td>\n",
              "      <td>0.943430</td>\n",
              "      <td>1.469141</td>\n",
              "      <td>...</td>\n",
              "      <td>-51.455950</td>\n",
              "      <td>0.819104</td>\n",
              "      <td>13.817479</td>\n",
              "      <td>0.691829</td>\n",
              "      <td>0.036880</td>\n",
              "      <td>1.469141</td>\n",
              "      <td>3.324323</td>\n",
              "      <td>0.618239</td>\n",
              "      <td>0.141644</td>\n",
              "      <td>0.055668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.938378</td>\n",
              "      <td>4.305605</td>\n",
              "      <td>2.689910</td>\n",
              "      <td>2.643387</td>\n",
              "      <td>0.338331</td>\n",
              "      <td>0.023024</td>\n",
              "      <td>0.338331</td>\n",
              "      <td>0.231497</td>\n",
              "      <td>0.180496</td>\n",
              "      <td>...</td>\n",
              "      <td>24.607247</td>\n",
              "      <td>0.067656</td>\n",
              "      <td>4.933978</td>\n",
              "      <td>0.143928</td>\n",
              "      <td>0.012843</td>\n",
              "      <td>0.180496</td>\n",
              "      <td>0.304480</td>\n",
              "      <td>0.083928</td>\n",
              "      <td>0.094402</td>\n",
              "      <td>0.082787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.641975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.260340</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>...</td>\n",
              "      <td>-138.520733</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>2.875434</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>1.481869</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.421325</td>\n",
              "      <td>0.887574</td>\n",
              "      <td>0.421325</td>\n",
              "      <td>0.769302</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>...</td>\n",
              "      <td>-68.735314</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>9.912027</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>3.152952</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.901308</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.919725</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>-48.164338</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>12.802302</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.036666</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>3.340923</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>0.914062</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>1.094141</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>...</td>\n",
              "      <td>-33.344173</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>16.398649</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.042855</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.540568</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.117647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.661453</td>\n",
              "      <td>0.956633</td>\n",
              "      <td>2.661453</td>\n",
              "      <td>2.302397</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.982275</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>34.614674</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.527247</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13fba12f-52dd-4848-92ce-37bd85cd5a50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13fba12f-52dd-4848-92ce-37bd85cd5a50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13fba12f-52dd-4848-92ce-37bd85cd5a50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c440eb47-b3f9-4c56-a9cc-dd8bad2e5ba4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c440eb47-b3f9-4c56-a9cc-dd8bad2e5ba4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c440eb47-b3f9-4c56-a9cc-dd8bad2e5ba4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          label         Length  Consonant_Count   Unique_Chars  \\\n",
              "count  694173.0  694173.000000    694173.000000  694173.000000   \n",
              "mean        1.0      19.226092        12.200742      12.481366   \n",
              "std         0.0       6.938378         4.305605       2.689910   \n",
              "min         1.0       8.000000         2.000000       4.000000   \n",
              "25%         1.0      14.000000         9.000000      10.000000   \n",
              "50%         1.0      18.000000        12.000000      12.000000   \n",
              "75%         1.0      25.000000        15.000000      14.000000   \n",
              "max         1.0      40.000000        27.000000      26.000000   \n",
              "\n",
              "       Max_Cons_Cluster       Dist_STD      Char_Gini  Char_Freq_Deviation  \\\n",
              "count     694173.000000  694173.000000  694173.000000        694173.000000   \n",
              "mean           4.576519       0.712628       0.897836             0.712628   \n",
              "std            2.643387       0.338331       0.023024             0.338331   \n",
              "min            1.000000       0.000000       0.641975             0.000000   \n",
              "25%            3.000000       0.421325       0.887574             0.421325   \n",
              "50%            4.000000       0.655555       0.901308             0.655555   \n",
              "75%            6.000000       0.942809       0.914062             0.942809   \n",
              "max           16.000000       2.661453       0.956633             2.661453   \n",
              "\n",
              "       KL_divergence  Compression_ratio  ...  Markov_Chain_Likelihood  \\\n",
              "count  694173.000000      694173.000000  ...            694173.000000   \n",
              "mean        0.943430           1.469141  ...               -51.455950   \n",
              "std         0.231497           0.180496  ...                24.607247   \n",
              "min         0.260340           0.885714  ...              -138.520733   \n",
              "25%         0.769302           1.320000  ...               -68.735314   \n",
              "50%         0.919725           1.444444  ...               -48.164338   \n",
              "75%         1.094141           1.571429  ...               -33.344173   \n",
              "max         2.302397           2.000000  ...               -10.982275   \n",
              "\n",
              "       Bigram_Likelihood  Ngram_LM_Perplexity  Unique_Char_Ratio  \\\n",
              "count      694173.000000        694173.000000      694173.000000   \n",
              "mean            0.819104            13.817479           0.691829   \n",
              "std             0.067656             4.933978           0.143928   \n",
              "min             0.156250             2.875434           0.305556   \n",
              "25%             0.769231             9.912027           0.566667   \n",
              "50%             0.823529            12.802302           0.687500   \n",
              "75%             0.880000            16.398649           0.812500   \n",
              "max             0.925000            34.614674           1.000000   \n",
              "\n",
              "       Norm_Char_Freq_Var  Kolmogorov_Complexity  Renyi_Entropy  \\\n",
              "count       694173.000000          694173.000000  694173.000000   \n",
              "mean             0.036880               1.469141       3.324323   \n",
              "std              0.012843               0.180496       0.304480   \n",
              "min              0.000000               0.885714       1.481869   \n",
              "25%              0.029215               1.320000       3.152952   \n",
              "50%              0.036666               1.444444       3.340923   \n",
              "75%              0.042855               1.571429       3.540568   \n",
              "max              0.177778               2.000000       4.527247   \n",
              "\n",
              "       Min_Levenshtein_to_Popular  Keyboard_Distance_Score  Sliding_Word_Ratio  \n",
              "count               694173.000000            694173.000000       694173.000000  \n",
              "mean                     0.618239                 0.141644            0.055668  \n",
              "std                      0.083928                 0.094402            0.082787  \n",
              "min                      0.142857                 0.000000            0.000000  \n",
              "25%                      0.567568                 0.071429            0.000000  \n",
              "50%                      0.615385                 0.133333            0.000000  \n",
              "75%                      0.666667                 0.212121            0.117647  \n",
              "max                      0.913043                 0.857143            0.625000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df=pd.read_csv(\"dga_18_version1.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1st74V2foA_G",
        "outputId": "395f6a58-9c3e-46df-b378-7a6fe23303e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Reordered CSV saved as dga_18_version2.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def reorder_columns(input_csv, output_csv, desired_order):\n",
        "    \"\"\"\n",
        "    Reorder the columns of a CSV file based on user-defined order.\n",
        "\n",
        "    Parameters:\n",
        "    - input_csv (str): Path to input CSV file.\n",
        "    - output_csv (str): Path to output CSV file with reordered columns.\n",
        "    - desired_order (list): List of column names in the desired order.\n",
        "    \"\"\"\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Check which desired columns exist\n",
        "    available_columns = [col for col in desired_order if col in df.columns]\n",
        "\n",
        "    # Add missing columns (if any were not in df)\n",
        "    missing_columns = [col for col in desired_order if col not in df.columns]\n",
        "    for col in missing_columns:\n",
        "        df[col] = None  # Fill with None or default values\n",
        "\n",
        "    # Reorder\n",
        "    df = df[available_columns + [col for col in df.columns if col not in available_columns]]\n",
        "\n",
        "    # Save output\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Reordered CSV saved as {output_csv}\")\n",
        "\n",
        "\n",
        "# =====================\n",
        "# Example usage\n",
        "# =====================\n",
        "\n",
        "# Suppose your dataset has 58 features + \"domain\" + \"label\"\n",
        "input_csv = \"dga_18_version1.csv\"\n",
        "output_csv = \"dga_18_version2.csv\"\n",
        "\n",
        "# User-defined column order (just an example)\n",
        "desired_order = [\n",
        "     #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",#\"Compression_ratio\",\n",
        "     #\"Pronounceability\",#\"Bigram_Score\",\n",
        "     #\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"Kolmogorov_Complexity\",\"Renyi_Entropy\",\"Min_Levenshtein_to_Popular\",\"Keyboard_Distance_Score\",\"Sliding_Word_Ratio\",\"label\"\n",
        "     #\"Kolmogorov_Complexity\"\n",
        "     # \"domain\",\"Length\",\"Consonant_Count\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "    #Digit_Count\", \"label\"\n",
        "       #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Pronounceability\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "    #\"domain\",\"Char_Freq_Deviation\",\"Unique_Char_Ratio\",\"label\"\n",
        "    #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "    #Digit_Count\", \"label\",\n",
        "    #\"Length\", \"Digit_Ratio\", \"Max_Consec_Digits\",\"Vowel_Count\", , , \"KL-divergence from benign char dist\",\n",
        "    #\"Compression ratio\", \"Pronounceability\", \"Bigram_Score\", \"Trigram_Score\",\n",
        "    #\"Alexa popularity bucket\", \"Homoglyph/brand-similarity (lookalike)\"\n",
        "]\n",
        "\n",
        "# Reorder dataset\n",
        "reorder_columns(input_csv, output_csv, desired_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "zDxpLmMNt7jS",
        "outputId": "7cdfa9ac-1248-4b1a-cec7-05e71ada77e7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6c2eb9e0-fbd3-4055-8a92-baf93ed0af8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Consonant_Count</th>\n",
              "      <th>Unique_Chars</th>\n",
              "      <th>Max_Cons_Cluster</th>\n",
              "      <th>Dist_STD</th>\n",
              "      <th>Char_Gini</th>\n",
              "      <th>Char_Freq_Deviation</th>\n",
              "      <th>KL_divergence</th>\n",
              "      <th>Compression_ratio</th>\n",
              "      <th>Pronounceability</th>\n",
              "      <th>...</th>\n",
              "      <th>Bigram_Likelihood</th>\n",
              "      <th>Ngram_LM_Perplexity</th>\n",
              "      <th>Unique_Char_Ratio</th>\n",
              "      <th>Norm_Char_Freq_Var</th>\n",
              "      <th>Kolmogorov_Complexity</th>\n",
              "      <th>Renyi_Entropy</th>\n",
              "      <th>Min_Levenshtein_to_Popular</th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "      <th>Sliding_Word_Ratio</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.000000</td>\n",
              "      <td>694173.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19.226092</td>\n",
              "      <td>12.200742</td>\n",
              "      <td>12.481366</td>\n",
              "      <td>4.576519</td>\n",
              "      <td>0.712628</td>\n",
              "      <td>0.897836</td>\n",
              "      <td>0.712628</td>\n",
              "      <td>0.943430</td>\n",
              "      <td>1.469141</td>\n",
              "      <td>0.466916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.819104</td>\n",
              "      <td>13.817479</td>\n",
              "      <td>0.691829</td>\n",
              "      <td>0.036880</td>\n",
              "      <td>1.469141</td>\n",
              "      <td>3.324323</td>\n",
              "      <td>0.618239</td>\n",
              "      <td>0.141644</td>\n",
              "      <td>0.055668</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.938378</td>\n",
              "      <td>4.305605</td>\n",
              "      <td>2.689910</td>\n",
              "      <td>2.643387</td>\n",
              "      <td>0.338331</td>\n",
              "      <td>0.023024</td>\n",
              "      <td>0.338331</td>\n",
              "      <td>0.231497</td>\n",
              "      <td>0.180496</td>\n",
              "      <td>0.246663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067656</td>\n",
              "      <td>4.933978</td>\n",
              "      <td>0.143928</td>\n",
              "      <td>0.012843</td>\n",
              "      <td>0.180496</td>\n",
              "      <td>0.304480</td>\n",
              "      <td>0.083928</td>\n",
              "      <td>0.094402</td>\n",
              "      <td>0.082787</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.641975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.260340</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>2.875434</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>1.481869</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.421325</td>\n",
              "      <td>0.887574</td>\n",
              "      <td>0.421325</td>\n",
              "      <td>0.769302</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>9.912027</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>3.152952</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.901308</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.919725</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>...</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>12.802302</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.036666</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>3.340923</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>0.914062</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>1.094141</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>...</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>16.398649</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.042855</td>\n",
              "      <td>1.571429</td>\n",
              "      <td>3.540568</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.212121</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.661453</td>\n",
              "      <td>0.956633</td>\n",
              "      <td>2.661453</td>\n",
              "      <td>2.302397</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>34.614674</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.177778</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.527247</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c2eb9e0-fbd3-4055-8a92-baf93ed0af8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c2eb9e0-fbd3-4055-8a92-baf93ed0af8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c2eb9e0-fbd3-4055-8a92-baf93ed0af8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9dd4f45b-cc79-4947-8896-a5a9ca4bbea2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9dd4f45b-cc79-4947-8896-a5a9ca4bbea2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9dd4f45b-cc79-4947-8896-a5a9ca4bbea2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              Length  Consonant_Count   Unique_Chars  Max_Cons_Cluster  \\\n",
              "count  694173.000000    694173.000000  694173.000000     694173.000000   \n",
              "mean       19.226092        12.200742      12.481366          4.576519   \n",
              "std         6.938378         4.305605       2.689910          2.643387   \n",
              "min         8.000000         2.000000       4.000000          1.000000   \n",
              "25%        14.000000         9.000000      10.000000          3.000000   \n",
              "50%        18.000000        12.000000      12.000000          4.000000   \n",
              "75%        25.000000        15.000000      14.000000          6.000000   \n",
              "max        40.000000        27.000000      26.000000         16.000000   \n",
              "\n",
              "            Dist_STD      Char_Gini  Char_Freq_Deviation  KL_divergence  \\\n",
              "count  694173.000000  694173.000000        694173.000000  694173.000000   \n",
              "mean        0.712628       0.897836             0.712628       0.943430   \n",
              "std         0.338331       0.023024             0.338331       0.231497   \n",
              "min         0.000000       0.641975             0.000000       0.260340   \n",
              "25%         0.421325       0.887574             0.421325       0.769302   \n",
              "50%         0.655555       0.901308             0.655555       0.919725   \n",
              "75%         0.942809       0.914062             0.942809       1.094141   \n",
              "max         2.661453       0.956633             2.661453       2.302397   \n",
              "\n",
              "       Compression_ratio  Pronounceability  ...  Bigram_Likelihood  \\\n",
              "count      694173.000000     694173.000000  ...      694173.000000   \n",
              "mean            1.469141          0.466916  ...           0.819104   \n",
              "std             0.180496          0.246663  ...           0.067656   \n",
              "min             0.885714          0.000000  ...           0.156250   \n",
              "25%             1.320000          0.250000  ...           0.769231   \n",
              "50%             1.444444          0.476190  ...           0.823529   \n",
              "75%             1.571429          0.608696  ...           0.880000   \n",
              "max             2.000000          4.000000  ...           0.925000   \n",
              "\n",
              "       Ngram_LM_Perplexity  Unique_Char_Ratio  Norm_Char_Freq_Var  \\\n",
              "count        694173.000000      694173.000000       694173.000000   \n",
              "mean             13.817479           0.691829            0.036880   \n",
              "std               4.933978           0.143928            0.012843   \n",
              "min               2.875434           0.305556            0.000000   \n",
              "25%               9.912027           0.566667            0.029215   \n",
              "50%              12.802302           0.687500            0.036666   \n",
              "75%              16.398649           0.812500            0.042855   \n",
              "max              34.614674           1.000000            0.177778   \n",
              "\n",
              "       Kolmogorov_Complexity  Renyi_Entropy  Min_Levenshtein_to_Popular  \\\n",
              "count          694173.000000  694173.000000               694173.000000   \n",
              "mean                1.469141       3.324323                    0.618239   \n",
              "std                 0.180496       0.304480                    0.083928   \n",
              "min                 0.885714       1.481869                    0.142857   \n",
              "25%                 1.320000       3.152952                    0.567568   \n",
              "50%                 1.444444       3.340923                    0.615385   \n",
              "75%                 1.571429       3.540568                    0.666667   \n",
              "max                 2.000000       4.527247                    0.913043   \n",
              "\n",
              "       Keyboard_Distance_Score  Sliding_Word_Ratio     label  \n",
              "count            694173.000000       694173.000000  694173.0  \n",
              "mean                  0.141644            0.055668       1.0  \n",
              "std                   0.094402            0.082787       0.0  \n",
              "min                   0.000000            0.000000       1.0  \n",
              "25%                   0.071429            0.000000       1.0  \n",
              "50%                   0.133333            0.000000       1.0  \n",
              "75%                   0.212121            0.117647       1.0  \n",
              "max                   0.857143            0.625000       1.0  \n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df=pd.read_csv(\"dga_18_version2.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN9YRACR0Xmo",
        "outputId": "bcf42413-2543-4366-c5e9-a2db5f94fd24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 694173\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset (replace with your file path)\n",
        "file_path = \"dga_18_version2.csv\"\n",
        "\n",
        "\n",
        "# Read dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Count number of rows\n",
        "row_count = len(df)\n",
        "\n",
        "print(f\"Number of rows in the dataset: {row_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "625r6eL319Nw",
        "outputId": "0f781d8a-b0ad-4051-e126-c7db8e6ddba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Filtered dataset (within bounds) saved to dga_18_version3.csv\n",
            "                            Lower_Bound  Upper_Bound\n",
            "Length                        -2.500000    41.500000\n",
            "Consonant_Count                0.000000    24.000000\n",
            "Unique_Chars                   4.000000    20.000000\n",
            "Max_Cons_Cluster              -1.500000    10.500000\n",
            "Dist_STD                      -0.360901     1.725035\n",
            "Char_Gini                      0.847841     0.953795\n",
            "Char_Freq_Deviation           -0.360901     1.725035\n",
            "KL_divergence                  0.282044     1.581399\n",
            "Compression_ratio              0.942857     1.948571\n",
            "Pronounceability              -0.288043     1.146739\n",
            "Bigram_Score                  -5.500000    38.500000\n",
            "Trigram_Score                 -6.500000    37.500000\n",
            "Markov_Chain_Likelihood     -121.822026    19.742540\n",
            "Bigram_Likelihood              0.603077     1.046154\n",
            "Ngram_LM_Perplexity            0.182094    26.128583\n",
            "Unique_Char_Ratio              0.197917     1.181250\n",
            "Norm_Char_Freq_Var             0.008755     0.063315\n",
            "Kolmogorov_Complexity          0.942857     1.948571\n",
            "Renyi_Entropy                  2.571527     4.121993\n",
            "Min_Levenshtein_to_Popular     0.418919     0.815315\n",
            "Keyboard_Distance_Score       -0.139610     0.423160\n",
            "Sliding_Word_Ratio            -0.176471     0.294118\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_outliers(df, feature_cols, method=\"iqr\", z_thresh=3, save_path=None):\n",
        "    \"\"\"\n",
        "    Filters datapoints outside the lower/upper bound for each feature\n",
        "    and optionally saves the datapoints that are within the bounds.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input dataset with features.\n",
        "    feature_cols : list\n",
        "        List of feature columns to check.\n",
        "    method : str\n",
        "        \"iqr\" (default) -> Interquartile Range method\n",
        "        \"zscore\" -> Standard deviation based\n",
        "    z_thresh : int\n",
        "        Threshold for zscore method\n",
        "    save_path : str or None\n",
        "        If provided, saves the filtered dataset to this CSV path.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame : Filtered dataset (within bounds)\n",
        "    pd.DataFrame : Bounds for each feature\n",
        "    \"\"\"\n",
        "    bounds = {}\n",
        "    df_filtered = df.copy()\n",
        "\n",
        "    for col in feature_cols:\n",
        "        if col not in df.columns:\n",
        "            continue  # skip missing features\n",
        "\n",
        "        series = df[col].dropna()\n",
        "\n",
        "        if method == \"iqr\":\n",
        "            Q1 = series.quantile(0.25)\n",
        "            Q3 = series.quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "\n",
        "        elif method == \"zscore\":\n",
        "            mean = series.mean()\n",
        "            std = series.std()\n",
        "            lower = mean - z_thresh * std\n",
        "            upper = mean + z_thresh * std\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n",
        "\n",
        "        bounds[col] = (lower, upper)\n",
        "\n",
        "        # keep only rows within bounds\n",
        "        df_filtered = df_filtered[(df_filtered[col] >= lower) & (df_filtered[col] <= upper)]\n",
        "\n",
        "    bounds_df = pd.DataFrame(bounds, index=[\"Lower_Bound\", \"Upper_Bound\"]).T\n",
        "\n",
        "    # Save filtered dataset if save_path provided\n",
        "    if save_path:\n",
        "        df_filtered.to_csv(save_path, index=False)\n",
        "        print(f\"✅ Filtered dataset (within bounds) saved to {save_path}\")\n",
        "\n",
        "    return df_filtered.reset_index(drop=True), bounds_df\n",
        "\n",
        "\n",
        "# ==== Example Usage ====\n",
        "all_features = [\n",
        "\n",
        "    #\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",#\"Compression_ratio\",\n",
        "    #\"Pronounceability\",#\"Bigram_Score\",\n",
        "    #\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "\n",
        "\n",
        "    #\"Kolmogorov_Complexity\"\n",
        "    #\"Max_Repeated_Char_Run\"\n",
        "\n",
        "\n",
        "    \"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"Kolmogorov_Complexity\",\"Renyi_Entropy\",\"Min_Levenshtein_to_Popular\",\"Keyboard_Distance_Score\",\"Sliding_Word_Ratio\"\n",
        "\n",
        "\n",
        "    #\"Renyi_Entropy\"\n",
        "    #\"Min_Levenshtein_to_Popular\"\n",
        "    #\"Keyboard_Distance_Score\"\n",
        "\n",
        "    #  \"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Pronounceability\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "    #\"Length\",\"Consonant_Count\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "    #\"Char_Freq_Deviation\",\"Unique_Char_Ratio\"\n",
        "    #\"Length\",\"Unique_Chars\",\"Dist_STD\",\"Char_Freq_Deviation\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Unique_Char_Ratio\"\n",
        "    #\"Compression_ratio\"\n",
        "\n",
        "   # \"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "   # \"Dist_STD\",\"Markov_Chain_Likelihood\"\n",
        "    #\"Length\",\"Unique_Chars\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "df = pd.read_csv(\"dga_18_version2.csv\")\n",
        "# Remove duplicate columns (keep first occurrence)\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Save filtered data to CSV\n",
        "df_filtered, bounds = filter_outliers(\n",
        "    df, all_features, method=\"iqr\", save_path=\"dga_18_version3.csv\"\n",
        ")\n",
        "\n",
        "print(bounds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "da5JtVP8Lfag",
        "outputId": "d9072259-431e-43ec-cab7-cb946216250d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c4f41767-161e-49f5-8282-364777c6935b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Consonant_Count</th>\n",
              "      <th>Unique_Chars</th>\n",
              "      <th>Max_Cons_Cluster</th>\n",
              "      <th>Dist_STD</th>\n",
              "      <th>Char_Gini</th>\n",
              "      <th>Char_Freq_Deviation</th>\n",
              "      <th>KL_divergence</th>\n",
              "      <th>Compression_ratio</th>\n",
              "      <th>Pronounceability</th>\n",
              "      <th>...</th>\n",
              "      <th>Bigram_Likelihood</th>\n",
              "      <th>Ngram_LM_Perplexity</th>\n",
              "      <th>Unique_Char_Ratio</th>\n",
              "      <th>Norm_Char_Freq_Var</th>\n",
              "      <th>Kolmogorov_Complexity</th>\n",
              "      <th>Renyi_Entropy</th>\n",
              "      <th>Min_Levenshtein_to_Popular</th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "      <th>Sliding_Word_Ratio</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.000000</td>\n",
              "      <td>572233.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>19.848646</td>\n",
              "      <td>12.490755</td>\n",
              "      <td>12.752150</td>\n",
              "      <td>4.330890</td>\n",
              "      <td>0.725677</td>\n",
              "      <td>0.900989</td>\n",
              "      <td>0.725677</td>\n",
              "      <td>0.915040</td>\n",
              "      <td>1.448823</td>\n",
              "      <td>0.476259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827141</td>\n",
              "      <td>14.232752</td>\n",
              "      <td>0.682994</td>\n",
              "      <td>0.036260</td>\n",
              "      <td>1.448823</td>\n",
              "      <td>3.359791</td>\n",
              "      <td>0.614898</td>\n",
              "      <td>0.139552</td>\n",
              "      <td>0.059090</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.775358</td>\n",
              "      <td>4.141531</td>\n",
              "      <td>2.508406</td>\n",
              "      <td>2.135666</td>\n",
              "      <td>0.317764</td>\n",
              "      <td>0.018044</td>\n",
              "      <td>0.317764</td>\n",
              "      <td>0.202885</td>\n",
              "      <td>0.167894</td>\n",
              "      <td>0.213786</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061562</td>\n",
              "      <td>4.634020</td>\n",
              "      <td>0.139425</td>\n",
              "      <td>0.009227</td>\n",
              "      <td>0.167894</td>\n",
              "      <td>0.259978</td>\n",
              "      <td>0.077071</td>\n",
              "      <td>0.087475</td>\n",
              "      <td>0.081459</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.229061</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.229061</td>\n",
              "      <td>0.386876</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>3.518005</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>0.012056</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>2.736966</td>\n",
              "      <td>0.419355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.433013</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>0.433013</td>\n",
              "      <td>0.752807</td>\n",
              "      <td>1.307692</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>10.823575</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.029463</td>\n",
              "      <td>1.307692</td>\n",
              "      <td>3.184425</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.655555</td>\n",
              "      <td>0.897360</td>\n",
              "      <td>1.421053</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>13.671606</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.036289</td>\n",
              "      <td>1.421053</td>\n",
              "      <td>3.369234</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>0.914127</td>\n",
              "      <td>0.942809</td>\n",
              "      <td>1.070826</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>16.398649</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>3.541659</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.724879</td>\n",
              "      <td>0.942222</td>\n",
              "      <td>1.724879</td>\n",
              "      <td>1.396110</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>1.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>25.931640</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.063311</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>4.113341</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4f41767-161e-49f5-8282-364777c6935b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4f41767-161e-49f5-8282-364777c6935b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4f41767-161e-49f5-8282-364777c6935b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7f9b9864-0532-408d-b75c-12e09730fc42\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f9b9864-0532-408d-b75c-12e09730fc42')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7f9b9864-0532-408d-b75c-12e09730fc42 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              Length  Consonant_Count   Unique_Chars  Max_Cons_Cluster  \\\n",
              "count  572233.000000    572233.000000  572233.000000     572233.000000   \n",
              "mean       19.848646        12.490755      12.752150          4.330890   \n",
              "std         6.775358         4.141531       2.508406          2.135666   \n",
              "min         9.000000         4.000000       8.000000          1.000000   \n",
              "25%        16.000000        10.000000      11.000000          3.000000   \n",
              "50%        19.000000        12.000000      13.000000          4.000000   \n",
              "75%        26.000000        15.000000      15.000000          6.000000   \n",
              "max        39.000000        24.000000      20.000000         10.000000   \n",
              "\n",
              "            Dist_STD      Char_Gini  Char_Freq_Deviation  KL_divergence  \\\n",
              "count  572233.000000  572233.000000        572233.000000  572233.000000   \n",
              "mean        0.725677       0.900989             0.725677       0.915040   \n",
              "std         0.317764       0.018044             0.317764       0.202885   \n",
              "min         0.229061       0.850000             0.229061       0.386876   \n",
              "25%         0.433013       0.890000             0.433013       0.752807   \n",
              "50%         0.655555       0.903226             0.655555       0.897360   \n",
              "75%         0.942809       0.914127             0.942809       1.070826   \n",
              "max         1.724879       0.942222             1.724879       1.396110   \n",
              "\n",
              "       Compression_ratio  Pronounceability  ...  Bigram_Likelihood  \\\n",
              "count      572233.000000     572233.000000  ...      572233.000000   \n",
              "mean            1.448823          0.476259  ...           0.827141   \n",
              "std             0.167894          0.213786  ...           0.061562   \n",
              "min             0.947368          0.000000  ...           0.607143   \n",
              "25%             1.307692          0.307692  ...           0.800000   \n",
              "50%             1.421053          0.500000  ...           0.842105   \n",
              "75%             1.500000          0.611111  ...           0.884615   \n",
              "max             1.888889          1.142857  ...           0.923077   \n",
              "\n",
              "       Ngram_LM_Perplexity  Unique_Char_Ratio  Norm_Char_Freq_Var  \\\n",
              "count        572233.000000      572233.000000       572233.000000   \n",
              "mean             14.232752           0.682994            0.036260   \n",
              "std               4.634020           0.139425            0.009227   \n",
              "min               3.518005           0.305556            0.012056   \n",
              "25%              10.823575           0.560000            0.029463   \n",
              "50%              13.671606           0.684211            0.036289   \n",
              "75%              16.398649           0.812500            0.041667   \n",
              "max              25.931640           0.947368            0.063311   \n",
              "\n",
              "       Kolmogorov_Complexity  Renyi_Entropy  Min_Levenshtein_to_Popular  \\\n",
              "count          572233.000000  572233.000000               572233.000000   \n",
              "mean                1.448823       3.359791                    0.614898   \n",
              "std                 0.167894       0.259978                    0.077071   \n",
              "min                 0.947368       2.736966                    0.419355   \n",
              "25%                 1.307692       3.184425                    0.567568   \n",
              "50%                 1.421053       3.369234                    0.615385   \n",
              "75%                 1.500000       3.541659                    0.666667   \n",
              "max                 1.888889       4.113341                    0.812500   \n",
              "\n",
              "       Keyboard_Distance_Score  Sliding_Word_Ratio     label  \n",
              "count            572233.000000       572233.000000  572233.0  \n",
              "mean                  0.139552            0.059090       1.0  \n",
              "std                   0.087475            0.081459       0.0  \n",
              "min                   0.000000            0.000000       1.0  \n",
              "25%                   0.071429            0.000000       1.0  \n",
              "50%                   0.133333            0.000000       1.0  \n",
              "75%                   0.200000            0.125000       1.0  \n",
              "max                   0.423077            0.294118       1.0  \n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df=pd.read_csv(\"dga_18_version3.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hBP6vJiG7LL",
        "outputId": "296ade53-50db-4694-c645-33937cd82628"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Features saved to domains_with_features.csv\n"
          ]
        }
      ],
      "source": [
        "# dga_feature_extractor.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import zlib\n",
        "import gzip\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "from difflib import SequenceMatcher\n",
        "from scipy.stats import entropy, kurtosis\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Download dictionary\n",
        "download('words')\n",
        "english_words = set(w.lower() for w in words.words())\n",
        "\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(string.ascii_lowercase) - VOWELS\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "\n",
        "# Example benign distribution (uniform)\n",
        "BENIGN_DIST = np.ones(26) / 26\n",
        "\n",
        "def shannon_entropy(s):\n",
        "    p, _ = np.histogram(list(s), bins=range(257), density=True)\n",
        "    p = p[p > 0]\n",
        "    return -np.sum(p * np.log2(p))\n",
        "\n",
        "def normalized_entropy(s):\n",
        "    if not s: return 0\n",
        "    return shannon_entropy(s) / math.log2(len(set(s)) + 1)\n",
        "\n",
        "def compress_ratio(s):\n",
        "    if not s: return 0\n",
        "    return len(zlib.compress(s.encode())) / max(1, len(s))\n",
        "\n",
        "def dict_word_features(domain):\n",
        "    matches = [w for w in english_words if w in domain]\n",
        "    longest = max((len(w) for w in matches), default=0)\n",
        "    return len(matches), longest, longest / max(1,len(domain))\n",
        "\n",
        "def sliding_dict_ratio(domain, window=4):\n",
        "    n = len(domain)\n",
        "    if n < window: return 0\n",
        "    matches = 0\n",
        "    for i in range(n - window + 1):\n",
        "        if domain[i:i+window] in english_words:\n",
        "            matches += 1\n",
        "    return matches / (n - window + 1)\n",
        "\n",
        "def vowel_consonant_alt(domain):\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    count = 0\n",
        "    for i in range(1, len(domain)):\n",
        "        if (domain[i] in VOWELS and domain[i-1] in CONSONANTS) or (domain[i] in CONSONANTS and domain[i-1] in VOWELS):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "def char_gini(s):\n",
        "    counts = Counter(s)\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    gini = 1 - sum((c/N)**2 for c in counts.values())\n",
        "    return gini\n",
        "\n",
        "def kl_divergence(s):\n",
        "    counts = Counter([c for c in s if c.isalpha()])\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    dist = np.array([counts.get(chr(97+i),0)/N for i in range(26)])\n",
        "    return entropy(dist, BENIGN_DIST)\n",
        "\n",
        "def markov_chain_likelihood(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    transitions = {}\n",
        "    for i in range(len(domain)-1):\n",
        "        pair = (domain[i], domain[i+1])\n",
        "        transitions[pair] = transitions.get(pair, 0) + 1\n",
        "    total = sum(transitions.values())\n",
        "    return sum(math.log((c/total)+1e-6) for c in transitions.values())\n",
        "\n",
        "def autocorrelation_score(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    values = [ord(c) for c in domain]\n",
        "    mean = np.mean(values)\n",
        "    var = np.var(values)\n",
        "    corr = sum((values[i]-mean)*(values[i+1]-mean) for i in range(len(values)-1)) / (var*(len(values)-1)+1e-6)\n",
        "    return corr\n",
        "\n",
        "def hyphen_word_match_ratio(domain):\n",
        "    \"\"\"Compute ratio of hyphen-separated parts that are valid dictionary words.\"\"\"\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts:\n",
        "        return 0.0\n",
        "    dict_matches = sum(1 for p in parts if p in english_words)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "# === Extra Feature Functions ===\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    \"\"\"Rényi entropy of order alpha (default α=2).\"\"\"\n",
        "    if not s:\n",
        "        return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs * np.log2(probs))  # Shannon\n",
        "    return 1 / (1 - alpha) * np.log2(np.sum(probs ** alpha))\n",
        "\n",
        "# Load top domains (free list like Tranco or Cisco Umbrella top domains)\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        popular_domains = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    popular_domains = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]  # fallback demo list\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    \"\"\"Compute minimum normalized Levenshtein distance to topN popular domains.\"\"\"\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in popular_domains[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio  # 0 = identical, 1 = very different\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "# Keyboard adjacency mapping\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q': \"was\", 'w': \"qase\", 'e': \"wsdr\", 'r': \"edft\", 't': \"rfgy\",\n",
        "    'y': \"tghu\", 'u': \"yhj\", 'i': \"ujk\", 'o': \"ikl\", 'p': \"ol\",\n",
        "    'a': \"qwsz\", 's': \"qwedxza\", 'd': \"erfcxs\", 'f': \"rtgvcd\", 'g': \"tyhbvf\",\n",
        "    'h': \"yujnbg\", 'j': \"uikmnh\", 'k': \"iolmj\", 'l': \"opk\",\n",
        "    'z': \"asx\", 'x': \"zsdc\", 'c': \"xdfv\", 'v': \"cfgb\", 'b': \"vghn\",\n",
        "    'n': \"bhjm\", 'm': \"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    \"\"\"Average keyboard adjacency match score between consecutive characters.\"\"\"\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    if len(domain) < 2:\n",
        "        return 0\n",
        "    score = 0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i], \"\"):\n",
        "            score += 1\n",
        "    return score / (len(domain)-1)\n",
        "\n",
        "# === Updated extract_features ===\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str):\n",
        "        domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    name, _, tld = domain.rpartition(\".\")\n",
        "    if not name:\n",
        "        name = domain\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "\n",
        "    feats = {}\n",
        "\n",
        "     # === Advanced Features Added ===\n",
        "    #feats[\"Renyi_Entropy\"] = renyi_entropy(domain, alpha=2)\n",
        "    #feats[\"Min_Levenshtein_to_Popular\"] = min_levenshtein_to_popular(domain)\n",
        "    feats[\"Keyboard_Distance_Score\"] = keyboard_distance_score(domain)\n",
        "\n",
        "\n",
        "    #feats[\"Length\"] = len(domain)\n",
        "    #feats[\"Consonant_Count\"] = sum(c in CONSONANTS for c in domain)\n",
        "    #feats[\"Unique_Chars\"] = len(set(domain))\n",
        "    #feats[\"Max_Cons_Cluster\"] = max((len(m.group()) for m in re.finditer(r'[bcdfghjklmnpqrstvwxyz]+', domain)), default=0)\n",
        "\n",
        "    # Info-theoretic\n",
        "    #feats[\"Dist_STD\"] = np.std([domain.count(c) for c in set(domain)])\n",
        "    #feats[\"Char_Gini\"] = char_gini(domain)\n",
        "    #feats[\"Char_Freq_Deviation\"] = np.std(list(Counter(domain).values()))\n",
        "    #feats[\"KL_divergence\"] = kl_divergence(domain)\n",
        "    #feats[\"Compression_ratio\"] = compress_ratio(domain)\n",
        "\n",
        "    # Pronounceability\n",
        "    #feats[\"Pronounceability\"] = sum(c in VOWELS for c in domain) / (sum(c in CONSONANTS for c in domain) + 1)\n",
        "\n",
        "    # N-gram / LM\n",
        "    #feats[\"Bigram_Score\"] = sum(1 for i in range(len(domain) - 1) if domain[i].isalpha() and domain[i + 1].isalpha())\n",
        "    #feats[\"Trigram_Score\"] = sum(1 for i in range(len(domain) - 2) if domain[i].isalpha() and domain[i + 2].isalpha())\n",
        "    #feats[\"Markov_Chain_Likelihood\"] = markov_chain_likelihood(domain)\n",
        "    #feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    #feats[\"Ngram_LM_Perplexity\"] = math.exp(-markov_chain_likelihood(domain) / max(1, len(domain)))\n",
        "\n",
        "    # Structural/pattern\n",
        "    #feats[\"Unique_Char_Ratio\"] = len(set(domain)) / max(1, len(domain))\n",
        "    #feats[\"Norm_Char_Freq_Var\"] = np.std(list(Counter(domain).values())) / max(1, len(domain))\n",
        "\n",
        "\n",
        "\n",
        "  #feats[\"Kolmogorov_Complexity\"] = compress_ratio(domain)\n",
        "\n",
        "    #feats[\"Max_Repeated_Char_Run\"] = max( (len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##feats[\"Digit_Count\"] = sum(c.isdigit() for c in domain)\n",
        "    ##feats[\"Digit_Ratio\"] = feats[\"Digit_Count\"]/max(1,len(domain))\n",
        "    ##feats[\"Max_Consec_Digits\"] = max((len(m.group()) for m in re.finditer(r'\\d+', domain)), default=0)\n",
        "    ##feats[\"Vowel_Count\"] = sum(c in VOWELS for c in domain)\n",
        "    ##feats[\"Has_Hyphen\"] = \"-\" in domain\n",
        "    ##feats[\"Hyphen_Placement_Score\"] = 1 if domain.startswith(\"-\") or domain.endswith(\"-\") else 0\n",
        "    ##feats[\"Hyphen_Word_Match_Ratio\"] = hyphen_word_match_ratio(domain)\n",
        "    ##feats[\"Subdomain_Depth\"] = domain.count(\".\")\n",
        "    ##feats[\"Entropy\"] = shannon_entropy(domain)\n",
        "    #feats[\"Normalized_Entropy\"] = normalized_entropy(domain)\n",
        "    ##feats[\"Vowel_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c in VOWELS]))\n",
        "    ##feats[\"Consonant_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c not in VOWELS and c.isalpha()]))\n",
        "    #dwc, lwl, lwr = dict_word_features(domain)\n",
        "    #feats[\"Dict_Word_Count\"] = dwc\n",
        "    #feats[\"Longest_Word_Len\"] = lwl\n",
        "    #feats[\"Longest_Word_Ratio\"] = lwr\n",
        "    #feats[\"Word_Match_Ratio\"] = dwc/max(1,len(domain.split(\".\")))\n",
        "    #feats[\"Sliding_Word_Ratio\"] = sliding_dict_ratio(domain)\n",
        "    ##feats[\"Vowel_Consonant_Alt\"] = vowel_consonant_alt(domain)\n",
        "    #feats[\"Lexical_Complexity\"] = shannon_entropy(domain)*len(set(domain))/max(1,len(domain))\n",
        "    #feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    #feats[\"TLD_Common\"] = 1 if f\".{tld}\" in POPULAR_TLDS else 0\n",
        "    ##feats[\"TLD_Bad_Score\"] = 1 if f\".{tld}\" in BAD_TLDS else 0\n",
        "    ##feats[\"Popular_Domain\"] = 0  # needs Alexa dataset\n",
        "    ##feats[\"Alexa_popularity_bucket\"] = -1\n",
        "    #feats[\"Repeat_Chars\"] = max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "    ##feats[\"Max_Repeated_Char_Run\"] = feats[\"Repeat_Chars\"]\n",
        "    ##feats[\"Digit_Letter_Alt_Count\"] = sum((domain[i].isdigit() != domain[i+1].isdigit()) for i in range(len(domain)-1))\n",
        "    #feats[\"Palindromic_Substring_Ratio\"] = sum(domain[i:j]==domain[i:j][::-1] for i in range(len(domain)) for j in range(i+2,len(domain)+1))/max(1,len(domain))\n",
        "    ##feats[\"First_Last_Char_Type\"] = int(domain[0].isalpha()) + int(domain[-1].isalpha())\n",
        "    ##feats[\"Shannon_Window_Entropy\"] = np.mean([shannon_entropy(domain[i:i+4]) for i in range(len(domain)-3)]) if len(domain)>=4 else  shannon_entropy(domain)\n",
        "    ##feats[\"Markov_Cross_Entropy\"] = shannon_entropy(domain) -  markov_chain_likelihood(domain)\n",
        "    ##feats[\"Permutation_Entropy\"] = shannon_entropy(domain)/max(1,math.log2(len(domain)))\n",
        "    #feats[\"RunLength_Entropy\"] = shannon_entropy(\"\".join([str(len(m.group())) for m in re.finditer(r'(.)\\1*', domain)]))\n",
        "    #feats[\"Dict_Word_Coverage\"] = dwc/max(1,len(domain))\n",
        "    #feats[\"Longest_Word_Suffix\"] = max((len(w) for w in english_words if domain.endswith(w)), default=0)\n",
        "    #feats[\"Word_Boundary_Count\"] = domain.count(\"-\")\n",
        "    #feats[\"Syllable_Count\"] = sum(domain.count(v) for v in VOWELS)\n",
        "    #feats[\"TLD_Length\"] = len(tld)\n",
        "    #feats[\"TLD_Rarity_Score\"] = 0 if f\".{tld}\" in POPULAR_TLDS else 1\n",
        "    #feats[\"Autocorrelation_Score\"] = autocorrelation_score(domain)\n",
        "    #feats[\"Hurst_Exponent\"] = 0.5  # placeholder\n",
        "\n",
        "    return feats\n",
        "\n",
        "# === Run on a dataset ===\n",
        "df = pd.read_csv(\"ndga_version2.csv\")  # must have \"domain\" column\n",
        "features = df[\"domain\"].apply(extract_features)\n",
        "feat_df = pd.DataFrame(list(features))\n",
        "out = pd.concat([df, feat_df], axis=1)\n",
        "out.to_csv(\"ndga_18_version1.csv\", index=False)\n",
        "print(\"✅ Features saved to domains_with_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ4gKCYnF5_2",
        "outputId": "6225de15-17db-4c1f-9579-e00b01cfef61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Features saved to domains_with_features.csv\n"
          ]
        }
      ],
      "source": [
        "# dga_feature_extractor.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import zlib\n",
        "import gzip\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "from difflib import SequenceMatcher\n",
        "from scipy.stats import entropy, kurtosis\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Download dictionary\n",
        "download('words')\n",
        "english_words = set(w.lower() for w in words.words())\n",
        "\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(string.ascii_lowercase) - VOWELS\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "\n",
        "# Example benign distribution (uniform)\n",
        "BENIGN_DIST = np.ones(26) / 26\n",
        "\n",
        "def shannon_entropy(s):\n",
        "    p, _ = np.histogram(list(s), bins=range(257), density=True)\n",
        "    p = p[p > 0]\n",
        "    return -np.sum(p * np.log2(p))\n",
        "\n",
        "def normalized_entropy(s):\n",
        "    if not s: return 0\n",
        "    return shannon_entropy(s) / math.log2(len(set(s)) + 1)\n",
        "\n",
        "def compress_ratio(s):\n",
        "    if not s: return 0\n",
        "    return len(zlib.compress(s.encode())) / max(1, len(s))\n",
        "\n",
        "def dict_word_features(domain):\n",
        "    matches = [w for w in english_words if w in domain]\n",
        "    longest = max((len(w) for w in matches), default=0)\n",
        "    return len(matches), longest, longest / max(1,len(domain))\n",
        "\n",
        "def sliding_dict_ratio(domain, window=4):\n",
        "    n = len(domain)\n",
        "    if n < window: return 0\n",
        "    matches = 0\n",
        "    for i in range(n - window + 1):\n",
        "        if domain[i:i+window] in english_words:\n",
        "            matches += 1\n",
        "    return matches / (n - window + 1)\n",
        "\n",
        "def vowel_consonant_alt(domain):\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    count = 0\n",
        "    for i in range(1, len(domain)):\n",
        "        if (domain[i] in VOWELS and domain[i-1] in CONSONANTS) or (domain[i] in CONSONANTS and domain[i-1] in VOWELS):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "def char_gini(s):\n",
        "    counts = Counter(s)\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    gini = 1 - sum((c/N)**2 for c in counts.values())\n",
        "    return gini\n",
        "\n",
        "def kl_divergence(s):\n",
        "    counts = Counter([c for c in s if c.isalpha()])\n",
        "    N = sum(counts.values())\n",
        "    if N == 0: return 0\n",
        "    dist = np.array([counts.get(chr(97+i),0)/N for i in range(26)])\n",
        "    return entropy(dist, BENIGN_DIST)\n",
        "\n",
        "def markov_chain_likelihood(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    transitions = {}\n",
        "    for i in range(len(domain)-1):\n",
        "        pair = (domain[i], domain[i+1])\n",
        "        transitions[pair] = transitions.get(pair, 0) + 1\n",
        "    total = sum(transitions.values())\n",
        "    return sum(math.log((c/total)+1e-6) for c in transitions.values())\n",
        "\n",
        "def autocorrelation_score(domain):\n",
        "    if len(domain) < 2: return 0\n",
        "    values = [ord(c) for c in domain]\n",
        "    mean = np.mean(values)\n",
        "    var = np.var(values)\n",
        "    corr = sum((values[i]-mean)*(values[i+1]-mean) for i in range(len(values)-1)) / (var*(len(values)-1)+1e-6)\n",
        "    return corr\n",
        "\n",
        "def hyphen_word_match_ratio(domain):\n",
        "    \"\"\"Compute ratio of hyphen-separated parts that are valid dictionary words.\"\"\"\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts:\n",
        "        return 0.0\n",
        "    dict_matches = sum(1 for p in parts if p in english_words)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "# === Extra Feature Functions ===\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    \"\"\"Rényi entropy of order alpha (default α=2).\"\"\"\n",
        "    if not s:\n",
        "        return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs * np.log2(probs))  # Shannon\n",
        "    return 1 / (1 - alpha) * np.log2(np.sum(probs ** alpha))\n",
        "\n",
        "# Load top domains (free list like Tranco or Cisco Umbrella top domains)\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        popular_domains = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    popular_domains = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]  # fallback demo list\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    \"\"\"Compute minimum normalized Levenshtein distance to topN popular domains.\"\"\"\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in popular_domains[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio  # 0 = identical, 1 = very different\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "# Keyboard adjacency mapping\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q': \"was\", 'w': \"qase\", 'e': \"wsdr\", 'r': \"edft\", 't': \"rfgy\",\n",
        "    'y': \"tghu\", 'u': \"yhj\", 'i': \"ujk\", 'o': \"ikl\", 'p': \"ol\",\n",
        "    'a': \"qwsz\", 's': \"qwedxza\", 'd': \"erfcxs\", 'f': \"rtgvcd\", 'g': \"tyhbvf\",\n",
        "    'h': \"yujnbg\", 'j': \"uikmnh\", 'k': \"iolmj\", 'l': \"opk\",\n",
        "    'z': \"asx\", 'x': \"zsdc\", 'c': \"xdfv\", 'v': \"cfgb\", 'b': \"vghn\",\n",
        "    'n': \"bhjm\", 'm': \"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    \"\"\"Average keyboard adjacency match score between consecutive characters.\"\"\"\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    if len(domain) < 2:\n",
        "        return 0\n",
        "    score = 0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i], \"\"):\n",
        "            score += 1\n",
        "    return score / (len(domain)-1)\n",
        "\n",
        "# === Updated extract_features ===\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str):\n",
        "        domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    name, _, tld = domain.rpartition(\".\")\n",
        "    if not name:\n",
        "        name = domain\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"Kolmogorov_Complexity\",\"Renyi_Entropy\",\"Min_Levenshtein_to_Popular\",\"Keyboard_Distance_Score\",\"Sliding_Word_Ratio\"\n",
        "\n",
        "    feats = {}\n",
        "\n",
        "\n",
        "\n",
        "    feats[\"Length\"] = len(domain)\n",
        "    feats[\"Consonant_Count\"] = sum(c in CONSONANTS for c in domain)\n",
        "    feats[\"Unique_Chars\"] = len(set(domain))\n",
        "    feats[\"Max_Cons_Cluster\"] = max((len(m.group()) for m in re.finditer(r'[bcdfghjklmnpqrstvwxyz]+', domain)), default=0)\n",
        "\n",
        "    # Info-theoretic\n",
        "    feats[\"Dist_STD\"] = np.std([domain.count(c) for c in set(domain)])\n",
        "    feats[\"Char_Gini\"] = char_gini(domain)\n",
        "    feats[\"Char_Freq_Deviation\"] = np.std(list(Counter(domain).values()))\n",
        "    feats[\"KL_divergence\"] = kl_divergence(domain)\n",
        "    feats[\"Compression_ratio\"] = compress_ratio(domain)\n",
        "\n",
        "    # Pronounceability\n",
        "    feats[\"Pronounceability\"] = sum(c in VOWELS for c in domain) / (sum(c in CONSONANTS for c in domain) + 1)\n",
        "\n",
        "    # N-gram / LM\n",
        "    feats[\"Bigram_Score\"] = sum(1 for i in range(len(domain) - 1) if domain[i].isalpha() and domain[i + 1].isalpha())\n",
        "    feats[\"Trigram_Score\"] = sum(1 for i in range(len(domain) - 2) if domain[i].isalpha() and domain[i + 2].isalpha())\n",
        "    feats[\"Markov_Chain_Likelihood\"] = markov_chain_likelihood(domain)\n",
        "    feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    feats[\"Ngram_LM_Perplexity\"] = math.exp(-markov_chain_likelihood(domain) / max(1, len(domain)))\n",
        "\n",
        "    # Structural/pattern\n",
        "    feats[\"Unique_Char_Ratio\"] = len(set(domain)) / max(1, len(domain))\n",
        "    feats[\"Norm_Char_Freq_Var\"] = np.std(list(Counter(domain).values())) / max(1, len(domain))\n",
        "\n",
        "\n",
        "\n",
        "    feats[\"Kolmogorov_Complexity\"] = compress_ratio(domain)\n",
        "\n",
        "   # === Advanced Features Added ===\n",
        "    feats[\"Renyi_Entropy\"] = renyi_entropy(domain, alpha=2)\n",
        "    feats[\"Min_Levenshtein_to_Popular\"] = min_levenshtein_to_popular(domain)\n",
        "    feats[\"Keyboard_Distance_Score\"] = keyboard_distance_score(domain)\n",
        "    feats[\"Sliding_Word_Ratio\"] = sliding_dict_ratio(domain)\n",
        "\n",
        "    #feats[\"Max_Repeated_Char_Run\"] = max( (len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##feats[\"Digit_Count\"] = sum(c.isdigit() for c in domain)\n",
        "    ##feats[\"Digit_Ratio\"] = feats[\"Digit_Count\"]/max(1,len(domain))\n",
        "    ##feats[\"Max_Consec_Digits\"] = max((len(m.group()) for m in re.finditer(r'\\d+', domain)), default=0)\n",
        "    ##feats[\"Vowel_Count\"] = sum(c in VOWELS for c in domain)\n",
        "    ##feats[\"Has_Hyphen\"] = \"-\" in domain\n",
        "    ##feats[\"Hyphen_Placement_Score\"] = 1 if domain.startswith(\"-\") or domain.endswith(\"-\") else 0\n",
        "    ##feats[\"Hyphen_Word_Match_Ratio\"] = hyphen_word_match_ratio(domain)\n",
        "    ##feats[\"Subdomain_Depth\"] = domain.count(\".\")\n",
        "    ##feats[\"Entropy\"] = shannon_entropy(domain)\n",
        "    #feats[\"Normalized_Entropy\"] = normalized_entropy(domain)\n",
        "    ##feats[\"Vowel_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c in VOWELS]))\n",
        "    ##feats[\"Consonant_Entropy\"] = shannon_entropy(\"\".join([c for c in domain if c not in VOWELS and c.isalpha()]))\n",
        "    #dwc, lwl, lwr = dict_word_features(domain)\n",
        "    #feats[\"Dict_Word_Count\"] = dwc\n",
        "    #feats[\"Longest_Word_Len\"] = lwl\n",
        "    #feats[\"Longest_Word_Ratio\"] = lwr\n",
        "    #feats[\"Word_Match_Ratio\"] = dwc/max(1,len(domain.split(\".\")))\n",
        "    #feats[\"Sliding_Word_Ratio\"] = sliding_dict_ratio(domain)\n",
        "    ##feats[\"Vowel_Consonant_Alt\"] = vowel_consonant_alt(domain)\n",
        "    #feats[\"Lexical_Complexity\"] = shannon_entropy(domain)*len(set(domain))/max(1,len(domain))\n",
        "    #feats[\"Bigram_Likelihood\"] = sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())/max(1,len(domain))\n",
        "    #feats[\"TLD_Common\"] = 1 if f\".{tld}\" in POPULAR_TLDS else 0\n",
        "    ##feats[\"TLD_Bad_Score\"] = 1 if f\".{tld}\" in BAD_TLDS else 0\n",
        "    ##feats[\"Popular_Domain\"] = 0  # needs Alexa dataset\n",
        "    ##feats[\"Alexa_popularity_bucket\"] = -1\n",
        "    #feats[\"Repeat_Chars\"] = max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0)\n",
        "    ##feats[\"Max_Repeated_Char_Run\"] = feats[\"Repeat_Chars\"]\n",
        "    ##feats[\"Digit_Letter_Alt_Count\"] = sum((domain[i].isdigit() != domain[i+1].isdigit()) for i in range(len(domain)-1))\n",
        "    #feats[\"Palindromic_Substring_Ratio\"] = sum(domain[i:j]==domain[i:j][::-1] for i in range(len(domain)) for j in range(i+2,len(domain)+1))/max(1,len(domain))\n",
        "    ##feats[\"First_Last_Char_Type\"] = int(domain[0].isalpha()) + int(domain[-1].isalpha())\n",
        "    ##feats[\"Shannon_Window_Entropy\"] = np.mean([shannon_entropy(domain[i:i+4]) for i in range(len(domain)-3)]) if len(domain)>=4 else  shannon_entropy(domain)\n",
        "    ##feats[\"Markov_Cross_Entropy\"] = shannon_entropy(domain) -  markov_chain_likelihood(domain)\n",
        "    ##feats[\"Permutation_Entropy\"] = shannon_entropy(domain)/max(1,math.log2(len(domain)))\n",
        "    #feats[\"RunLength_Entropy\"] = shannon_entropy(\"\".join([str(len(m.group())) for m in re.finditer(r'(.)\\1*', domain)]))\n",
        "    #feats[\"Dict_Word_Coverage\"] = dwc/max(1,len(domain))\n",
        "    #feats[\"Longest_Word_Suffix\"] = max((len(w) for w in english_words if domain.endswith(w)), default=0)\n",
        "    #feats[\"Word_Boundary_Count\"] = domain.count(\"-\")\n",
        "    #feats[\"Syllable_Count\"] = sum(domain.count(v) for v in VOWELS)\n",
        "    #feats[\"TLD_Length\"] = len(tld)\n",
        "    #feats[\"TLD_Rarity_Score\"] = 0 if f\".{tld}\" in POPULAR_TLDS else 1\n",
        "    #feats[\"Autocorrelation_Score\"] = autocorrelation_score(domain)\n",
        "    #feats[\"Hurst_Exponent\"] = 0.5  # placeholder\n",
        "\n",
        "    return feats\n",
        "\n",
        "# === Run on a dataset ===\n",
        "df = pd.read_csv(\"ndga_version2.csv\")  # must have \"domain\" column\n",
        "features = df[\"domain\"].apply(extract_features)\n",
        "feat_df = pd.DataFrame(list(features))\n",
        "out = pd.concat([df, feat_df], axis=1)\n",
        "out.to_csv(\"ndga_18_version1.csv\", index=False)\n",
        "print(\"✅ Features saved to domains_with_features.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "r60A5qIvHCmu",
        "outputId": "88a670c8-3b11-410b-c99f-80482d3f9752"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353559.75455430447,\n        \"min\": 0.0,\n        \"max\": 1000018.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1000018.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Keyboard_Distance_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353559.6760788214,\n        \"min\": 0.0,\n        \"max\": 1000018.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1000018.0,\n          0.1289532749477058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dd3e9457-a3ad-4020-b651-96fe9797cb2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000018.0</td>\n",
              "      <td>1.000018e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.289533e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.136739e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.111111e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd3e9457-a3ad-4020-b651-96fe9797cb2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd3e9457-a3ad-4020-b651-96fe9797cb2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd3e9457-a3ad-4020-b651-96fe9797cb2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1804be31-0582-4567-bf47-02be69b400a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1804be31-0582-4567-bf47-02be69b400a3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1804be31-0582-4567-bf47-02be69b400a3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           label  Keyboard_Distance_Score\n",
              "count  1000018.0             1.000018e+06\n",
              "mean         0.0             1.289533e-01\n",
              "std          0.0             1.136739e-01\n",
              "min          0.0             0.000000e+00\n",
              "25%          0.0             0.000000e+00\n",
              "50%          0.0             1.111111e-01\n",
              "75%          0.0             2.000000e-01\n",
              "max          0.0             1.000000e+00"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "df=pd.read_csv(\"ndga_18_version1.csv\")\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2b-L5WUHJee",
        "outputId": "40039e6c-a0a9-417e-9059-1a66d2955f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Reordered CSV saved as ndga_18_version2.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def reorder_columns(input_csv, output_csv, desired_order):\n",
        "    \"\"\"\n",
        "    Reorder the columns of a CSV file based on user-defined order.\n",
        "\n",
        "    Parameters:\n",
        "    - input_csv (str): Path to input CSV file.\n",
        "    - output_csv (str): Path to output CSV file with reordered columns.\n",
        "    - desired_order (list): List of column names in the desired order.\n",
        "    \"\"\"\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Check which desired columns exist\n",
        "    available_columns = [col for col in desired_order if col in df.columns]\n",
        "\n",
        "    # Add missing columns (if any were not in df)\n",
        "    missing_columns = [col for col in desired_order if col not in df.columns]\n",
        "    for col in missing_columns:\n",
        "        df[col] = None  # Fill with None or default values\n",
        "\n",
        "    # Reorder\n",
        "    df = df[available_columns + [col for col in df.columns if col not in available_columns]]\n",
        "\n",
        "    # Save output\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Reordered CSV saved as {output_csv}\")\n",
        "\n",
        "\n",
        "# =====================\n",
        "# Example usage\n",
        "# =====================\n",
        "\n",
        "# Suppose your dataset has 58 features + \"domain\" + \"label\"\n",
        "input_csv = \"ndga_18_version1.csv\"\n",
        "output_csv = \"ndga_18_version2.csv\"\n",
        "\n",
        "# User-defined column order (just an example)\n",
        "desired_order = [\n",
        "\n",
        "     # \"domain\",\"Char_Freq_Deviation\",\"Unique_Char_Ratio\",\"label\"\n",
        "      #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "     #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",#\"Compression_ratio\",\n",
        "     #\"Pronounceability\",#\"Bigram_Score\",\n",
        "     #\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "\n",
        "     \"domain\",\"Keyboard_Distance_Score\",\"label\"\n",
        "\n",
        "     #\"Min_Levenshtein_to_Popular\"\n",
        "\n",
        "\n",
        "     #\"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Pronounceability\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "     #\"domain\",\"Length\",\"Consonant_Count\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "    #\"domain\",\"Length\",\"Unique_Chars\",\"Dist_STD\",\"Char_Freq_Deviation\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Unique_Char_Ratio\",\"label\"\n",
        "    #Digit_Count\", \"label\",\n",
        "   # \"domain\",\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\",\"label\"\n",
        "    #\"Length\", \"Digit_Ratio\", \"Max_Consec_Digits\",\"Vowel_Count\", , , \"KL-divergence from benign char dist\",\n",
        "    #\"Compression ratio\", \"Pronounceability\", \"Bigram_Score\", \"Trigram_Score\",\n",
        "    #\"Alexa popularity bucket\", \"Homoglyph/brand-similarity (lookalike)\"\n",
        "]\n",
        "\n",
        "# Reorder dataset\n",
        "reorder_columns(input_csv, output_csv, desired_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToVKYzVoyVGf",
        "outputId": "36ba7ba4-1b0c-478f-f665-541f208fd25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 1000018\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset (replace with your file path)\n",
        "file_path = \"ndga_18_version2.csv\"\n",
        "\n",
        "\n",
        "# Read dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Count number of rows\n",
        "row_count = len(df)\n",
        "\n",
        "print(f\"Number of rows in the dataset: {row_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KnrfgRk75cjs",
        "outputId": "eef456c6-3087-4d9d-ff69-a70823eaf577"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Keyboard_Distance_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353559.6760788214,\n        \"min\": 0.0,\n        \"max\": 1000018.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1000018.0,\n          0.1289532749477058,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 353559.75455430447,\n        \"min\": 0.0,\n        \"max\": 1000018.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1000018.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9ba09dd8-9bd3-4cbd-91ed-b68a1f7d758e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000018e+06</td>\n",
              "      <td>1000018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.289533e-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.136739e-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.111111e-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000e-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ba09dd8-9bd3-4cbd-91ed-b68a1f7d758e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ba09dd8-9bd3-4cbd-91ed-b68a1f7d758e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ba09dd8-9bd3-4cbd-91ed-b68a1f7d758e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe3f7fce-4b5c-4881-bce6-47ed819b4afd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe3f7fce-4b5c-4881-bce6-47ed819b4afd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe3f7fce-4b5c-4881-bce6-47ed819b4afd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Keyboard_Distance_Score      label\n",
              "count             1.000018e+06  1000018.0\n",
              "mean              1.289533e-01        0.0\n",
              "std               1.136739e-01        0.0\n",
              "min               0.000000e+00        0.0\n",
              "25%               0.000000e+00        0.0\n",
              "50%               1.111111e-01        0.0\n",
              "75%               2.000000e-01        0.0\n",
              "max               1.000000e+00        0.0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df=pd.read_csv(\"ndga_18_version2.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfZatVK9yYXe",
        "outputId": "dd6213b6-9bdd-4141-ed7e-6e09ba1d8cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Filtered dataset (within bounds) saved to ndga_18_version3.csv\n",
            "                         Lower_Bound  Upper_Bound\n",
            "Keyboard_Distance_Score         -0.3          0.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_outliers(df, feature_cols, method=\"iqr\", z_thresh=3, save_path=None):\n",
        "    \"\"\"\n",
        "    Filters datapoints outside the lower/upper bound for each feature\n",
        "    and optionally saves the datapoints that are within the bounds.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input dataset with features.\n",
        "    feature_cols : list\n",
        "        List of feature columns to check.\n",
        "    method : str\n",
        "        \"iqr\" (default) -> Interquartile Range method\n",
        "        \"zscore\" -> Standard deviation based\n",
        "    z_thresh : int\n",
        "        Threshold for zscore method\n",
        "    save_path : str or None\n",
        "        If provided, saves the filtered dataset to this CSV path.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame : Filtered dataset (within bounds)\n",
        "    pd.DataFrame : Bounds for each feature\n",
        "    \"\"\"\n",
        "    bounds = {}\n",
        "    df_filtered = df.copy()\n",
        "\n",
        "    for col in feature_cols:\n",
        "        if col not in df.columns:\n",
        "            continue  # skip missing features\n",
        "\n",
        "        series = df[col].dropna()\n",
        "\n",
        "        if method == \"iqr\":\n",
        "            Q1 = series.quantile(0.25)\n",
        "            Q3 = series.quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "\n",
        "        elif method == \"zscore\":\n",
        "            mean = series.mean()\n",
        "            std = series.std()\n",
        "            lower = mean - z_thresh * std\n",
        "            upper = mean + z_thresh * std\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'iqr' or 'zscore'\")\n",
        "\n",
        "        bounds[col] = (lower, upper)\n",
        "\n",
        "        # keep only rows within bounds\n",
        "        df_filtered = df_filtered[(df_filtered[col] >= lower) & (df_filtered[col] <= upper)]\n",
        "\n",
        "    bounds_df = pd.DataFrame(bounds, index=[\"Lower_Bound\", \"Upper_Bound\"]).T\n",
        "\n",
        "    # Save filtered dataset if save_path provided\n",
        "    if save_path:\n",
        "        df_filtered.to_csv(save_path, index=False)\n",
        "        print(f\"✅ Filtered dataset (within bounds) saved to {save_path}\")\n",
        "\n",
        "    return df_filtered.reset_index(drop=True), bounds_df\n",
        "\n",
        "\n",
        "# ==== Example Usage ====\n",
        "all_features = [\n",
        "\n",
        "    #\"Char_Freq_Deviation\",\"Unique_Char_Ratio\"\n",
        "    #\"Length\",\"Consonant_Count\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "    #\"Dist_STD\",\"Markov_Chain_Likelihood\"\n",
        "\n",
        "   #\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",#\"Compression_ratio\",\n",
        "   # \"Pronounceability\",#\"Bigram_Score\",\n",
        "    #\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "    #\"Min_Levenshtein_to_Popular\"\n",
        "    \"Keyboard_Distance_Score\"\n",
        "    #\"Renyi_Entropy\"\n",
        "    #\"Kolmogorov_Complexity\"\n",
        "    #\"Max_Repeated_Char_Run\"\n",
        "    #\"\n",
        "    #\n",
        "\n",
        "    #\"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Pronounceability\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Bigram_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "    #\"Length\",\"Unique_Chars\",\"Dist_STD\",\"Char_Freq_Deviation\",\"Compression_ratio\",\"Bigram_Score\",\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Unique_Char_Ratio\"\n",
        "   # \"Vowel_Consonant_Alt\"\n",
        "\n",
        "   # \"Length\",\"Consonant_Count\",\"Unique_Chars\",\"Max_Cons_Cluster\",\"Dist_STD\",\"Char_Gini\",\"Char_Freq_Deviation\",\"KL_divergence\",\"Compression_ratio\",\"Pronounceability\",\"Bigram_Score\",\n",
        "    #\"Trigram_Score\",\"Markov_Chain_Likelihood\",\"Ngram_LM_Perplexity\",\"Unique_Char_Ratio\",\"Norm_Char_Freq_Var\"\n",
        "\n",
        "]\n",
        "\n",
        "df = pd.read_csv(\"ndga_18_version2.csv\")\n",
        "\n",
        "# Save filtered data to CSV\n",
        "df_filtered, bounds = filter_outliers(\n",
        "    df, all_features, method=\"iqr\", save_path=\"ndga_18_version3.csv\"\n",
        ")\n",
        "\n",
        "print(bounds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkGJ7DJNpYQU",
        "outputId": "daa25fd6-d99f-4db8-98de-a254a3619bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       domain  Keyboard_Distance_Score  label\n",
            "0                  0-0.online                 0.000000      0\n",
            "1                  0-0szd.com                 0.400000      0\n",
            "2                      0-1.ir                 0.000000      0\n",
            "3       0-100australia.com.au                 0.076923      0\n",
            "4              0-18klinik.com                 0.250000      0\n",
            "...                       ...                      ...    ...\n",
            "680163            plumpos.com                 0.222222      0\n",
            "680164            plumpwc.com                 0.111111      0\n",
            "680165        plumpyfield.com                 0.153846      0\n",
            "680166               plumr.de                 0.500000      0\n",
            "680167        plums-plain.com                 0.166667      0\n",
            "\n",
            "[680168 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def select_entries(file, num_entries, output_file=\"ndga_18_version4.csv\"):\n",
        "    \"\"\"\n",
        "    Select the user-specified number of entries (rows) from a dataset.\n",
        "\n",
        "    Args:\n",
        "        file (str): Path to the CSV file.\n",
        "\n",
        "        num_entries (int): Number of rows to select.\n",
        "        output_file (str): File to save the selected rows.\n",
        "    \"\"\"\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Select first 'num_entries' rows\n",
        "    selected_df = df.head(num_entries)\n",
        "\n",
        "    # Save result\n",
        "    selected_df.to_csv(output_file, index=False)\n",
        "\n",
        "\n",
        "    return selected_df\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "selected = select_entries(\"ndga_18_version3.csv\", 680168 )   # get first 100 rows\n",
        "print(selected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BkqP9WKc4z9N",
        "outputId": "77b050c4-3095-48f8-857b-d39a53a8bab2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Keyboard_Distance_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 240475.65056206545,\n        \"min\": 0.0,\n        \"max\": 680168.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          680168.0,\n          0.12290071047580972,\n          0.1875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 240475.70257304583,\n        \"min\": 0.0,\n        \"max\": 680168.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          680168.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1a0958ff-eb7f-41db-b1a5-62fb27c669fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Keyboard_Distance_Score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>680168.000000</td>\n",
              "      <td>680168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.122901</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.108254</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a0958ff-eb7f-41db-b1a5-62fb27c669fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a0958ff-eb7f-41db-b1a5-62fb27c669fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a0958ff-eb7f-41db-b1a5-62fb27c669fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e628c6c0-e5bd-4823-a26f-7d22791856dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e628c6c0-e5bd-4823-a26f-7d22791856dd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e628c6c0-e5bd-4823-a26f-7d22791856dd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Keyboard_Distance_Score     label\n",
              "count            680168.000000  680168.0\n",
              "mean                  0.122901       0.0\n",
              "std                   0.108254       0.0\n",
              "min                   0.000000       0.0\n",
              "25%                   0.000000       0.0\n",
              "50%                   0.111111       0.0\n",
              "75%                   0.187500       0.0\n",
              "max                   0.500000       0.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "df=pd.read_csv(\"ndga_18_version4.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbUWHoRY42gu",
        "outputId": "51f6ea9a-30aa-478f-dcb9-6187ec1b0f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                domain  Keyboard_Distance_Score  label\n",
            "0  ofdhiydrrttpblp.com                 0.235294      1\n",
            "1  puciftnfkplcbhp.net                 0.176471      1\n",
            "2  bowjjxxnhkyvygk.biz                 0.117647      1\n",
            "3   osvwkptpwqyiqen.ru                 0.062500      1\n",
            "4  cpmjpnwdgbxyyql.org                 0.176471      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def combine_datasets(file1, file2, output_file=\"combined.csv\"):\n",
        "    \"\"\"\n",
        "    Combine two datasets without altering datapoints.\n",
        "    The header of the second dataset is removed automatically.\n",
        "    \"\"\"\n",
        "    # Load first dataset normally (with header)\n",
        "    df1 = pd.read_csv(file1)\n",
        "\n",
        "    # Load second dataset as raw, then reassign columns from df1\n",
        "    df2 = pd.read_csv(file2, header=None, skiprows=1)\n",
        "    df2.columns = df1.columns  # assign the same header as df1\n",
        "\n",
        "    # Concatenate without altering datapoints\n",
        "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    combined_df.to_csv(output_file, index=False)\n",
        "    return combined_df\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "combined = combine_datasets(\"dga_18_version3.csv\", \"ndga_18_version4.csv\")\n",
        "print(combined.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcVPDQAA45E1",
        "outputId": "44c8b250-bec2-4476-f56c-3eb841e796e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o84Xm4QN17cc",
        "outputId": "1170ffdf-944d-49c2-9603-ebe102a42a35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [18:23:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7009483143109915\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71    136596\n",
            "           1       0.71      0.67      0.69    136942\n",
            "\n",
            "    accuracy                           0.70    273538\n",
            "   macro avg       0.70      0.70      0.70    273538\n",
            "weighted avg       0.70      0.70      0.70    273538\n",
            "\n",
            "✅ Model saved to dga_model.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import zlib\n",
        "import string\n",
        "import joblib\n",
        "from collections import Counter\n",
        "from difflib import SequenceMatcher\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# -------------------------\n",
        "# Download English words\n",
        "# -------------------------\n",
        "try:\n",
        "    download('words')\n",
        "    ENGLISH_WORDS = set(w.lower() for w in words.words())\n",
        "except:\n",
        "    ENGLISH_WORDS = {\"test\",\"shop\",\"login\",\"home\",\"mail\",\"secure\"}  # fallback\n",
        "\n",
        "# -------------------------\n",
        "# Constants\n",
        "# -------------------------\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(string.ascii_lowercase) - VOWELS\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "BENIGN_DIST = np.ones(26)/26  # uniform for KL divergence\n",
        "\n",
        "# -------------------------\n",
        "# Load top domains\n",
        "# -------------------------\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        POPULAR_DOMAINS = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    POPULAR_DOMAINS = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]\n",
        "\n",
        "# -------------------------\n",
        "# Feature Functions\n",
        "# -------------------------\n",
        "def shannon_entropy(s):\n",
        "    if not s: return 0\n",
        "    p, _ = np.histogram(list(s), bins=range(257), density=True)\n",
        "    p = p[p>0]\n",
        "    return -np.sum(p*np.log2(p))\n",
        "\n",
        "def normalized_entropy(s):\n",
        "    if not s: return 0\n",
        "    return shannon_entropy(s)/math.log2(len(set(s))+1)\n",
        "\n",
        "def compress_ratio(s):\n",
        "    if not s: return 0\n",
        "    return len(zlib.compress(s.encode()))/max(1,len(s))\n",
        "\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    if not s: return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs*np.log2(probs))\n",
        "    return 1/(1-alpha) * np.log2(np.sum(probs**alpha))\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in POPULAR_DOMAINS[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "# -------------------------\n",
        "# Keyboard adjacency mapping\n",
        "# -------------------------\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q':\"was\",'w':\"qase\",'e':\"wsdr\",'r':\"edft\",'t':\"rfgy\",\n",
        "    'y':\"tghu\",'u':\"yhj\",'i':\"ujk\",'o':\"ikl\",'p':\"ol\",\n",
        "    'a':\"qwsz\",'s':\"qwedxza\",'d':\"erfcxs\",'f':\"rtgvcd\",'g':\"tyhbvf\",\n",
        "    'h':\"yujnbg\",'j':\"uikmnh\",'k':\"iolmj\",'l':\"opk\",\n",
        "    'z':\"asx\",'x':\"zsdc\",'c':\"xdfv\",'v':\"cfgb\",'b':\"vghn\",\n",
        "    'n':\"bhjm\",'m':\"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    domain = re.sub(r'[^a-z]','',domain.lower())\n",
        "    if len(domain)<2: return 0\n",
        "    score=0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i],\"\"):\n",
        "            score+=1\n",
        "    return score/(len(domain)-1)\n",
        "\n",
        "# -------------------------\n",
        "# Word / Lexical Features\n",
        "# -------------------------\n",
        "def dict_word_features(domain):\n",
        "    matches = [w for w in ENGLISH_WORDS if w in domain]\n",
        "    longest = max((len(w) for w in matches), default=0)\n",
        "    return len(matches), longest, longest/max(1,len(domain))\n",
        "\n",
        "def sliding_dict_ratio(domain, window=4):\n",
        "    n=len(domain)\n",
        "    if n<window: return 0\n",
        "    matches=0\n",
        "    for i in range(n-window+1):\n",
        "        if domain[i:i+window] in ENGLISH_WORDS:\n",
        "            matches+=1\n",
        "    return matches/(n-window+1)\n",
        "\n",
        "def vowel_consonant_alt(domain):\n",
        "    domain=re.sub(r'[^a-z]','',domain.lower())\n",
        "    count=0\n",
        "    for i in range(1,len(domain)):\n",
        "        if (domain[i] in VOWELS and domain[i-1] in CONSONANTS) or (domain[i] in CONSONANTS and domain[i-1] in VOWELS):\n",
        "            count+=1\n",
        "    return count\n",
        "\n",
        "def char_gini(s):\n",
        "    counts=Counter(s)\n",
        "    N=sum(counts.values())\n",
        "    if N==0: return 0\n",
        "    return 1 - sum((c/N)**2 for c in counts.values())\n",
        "\n",
        "def kl_divergence(s):\n",
        "    counts=Counter([c for c in s if c.isalpha()])\n",
        "    N=sum(counts.values())\n",
        "    if N==0: return 0\n",
        "    dist=np.array([counts.get(chr(97+i),0)/N for i in range(26)])\n",
        "    return entropy(dist, BENIGN_DIST)\n",
        "\n",
        "def markov_chain_likelihood(domain):\n",
        "    if len(domain)<2: return 0\n",
        "    transitions={}\n",
        "    for i in range(len(domain)-1):\n",
        "        pair=(domain[i],domain[i+1])\n",
        "        transitions[pair]=transitions.get(pair,0)+1\n",
        "    total=sum(transitions.values())\n",
        "    return sum(math.log((c/total)+1e-6) for c in transitions.values())\n",
        "\n",
        "def autocorrelation_score(domain):\n",
        "    if len(domain)<2: return 0\n",
        "    vals=[ord(c) for c in domain]\n",
        "    mean=np.mean(vals)\n",
        "    var=np.var(vals)\n",
        "    return sum((vals[i]-mean)*(vals[i+1]-mean) for i in range(len(vals)-1))/(var*(len(vals)-1)+1e-6)\n",
        "\n",
        "def hyphen_word_match_ratio(domain):\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts: return 0\n",
        "    dict_matches = sum(1 for p in parts if p in ENGLISH_WORDS)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "def max_cons_cluster(domain):\n",
        "    return max((len(m.group()) for m in re.finditer(r\"[bcdfghjklmnpqrstvwxyz]+\", domain.lower())), default=0)\n",
        "\n",
        "def consonant_count(domain):\n",
        "    return sum(c in CONSONANTS for c in domain.lower())\n",
        "\n",
        "def vowel_count(domain):\n",
        "    return sum(c in VOWELS for c in domain.lower())\n",
        "\n",
        "def pronouncability_score(domain):\n",
        "    return vowel_count(domain)/ (consonant_count(domain)+1)\n",
        "\n",
        "def bigram_score(domain):\n",
        "    return sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())\n",
        "\n",
        "def trigram_score(domain):\n",
        "    return sum(1 for i in range(len(domain)-2) if domain[i].isalpha() and domain[i+2].isalpha())\n",
        "\n",
        "def ngram_lm_perplexity(domain):\n",
        "    likelihood = markov_chain_likelihood(domain)\n",
        "    if len(domain)==0:\n",
        "        return 0\n",
        "    return math.exp(-likelihood / len(domain))\n",
        "\n",
        "def char_freq_deviation(domain):\n",
        "    counts = list(Counter(domain).values())\n",
        "    return np.std(counts) if counts else 0\n",
        "\n",
        "def normal_char_freq_variance(domain):\n",
        "    counts = list(Counter(domain).values())\n",
        "    return (np.std(counts)/len(domain)) if domain else 0\n",
        "def min_levenshtein_to_popular(domain, popular_list=None):\n",
        "    \"\"\"\n",
        "    Compute minimum Levenshtein distance of domain to a list of popular domains.\n",
        "    \"\"\"\n",
        "    if popular_list is None:\n",
        "        popular_list = [\"google.com\", \"facebook.com\", \"youtube.com\", \"amazon.com\", \"wikipedia.org\",\n",
        "                        \"twitter.com\", \"instagram.com\", \"linkedin.com\", \"netflix.com\", \"yahoo.com\"]\n",
        "\n",
        "    domain = domain.lower()\n",
        "    min_dist = float(\"inf\")\n",
        "\n",
        "    for pd in popular_list:\n",
        "        # Simple Levenshtein via SequenceMatcher ratio\n",
        "        ratio = difflib.SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = max(len(domain), len(pd)) * (1 - ratio)   # convert similarity → distance\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "\n",
        "    return min_dist\n",
        "\n",
        "# -------------------------\n",
        "# Main feature extractor\n",
        "# -------------------------\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str): domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    dwc, lwl, lwr = dict_word_features(domain)\n",
        "    tld = domain.split(\".\")[-1] if \".\" in domain else \"\"\n",
        "\n",
        "    digits = [c for c in domain if c.isdigit()]\n",
        "    max_consec_digits = max((len(m.group()) for m in re.finditer(r'\\d+', domain)), default=0)\n",
        "    has_hyphen = 1 if \"-\" in domain else 0\n",
        "\n",
        "    feats = {\n",
        "        # === Core Structural Features ===\n",
        "        \"Length\": len(domain),\n",
        "        \"Unique_Chars\": len(set(domain)),\n",
        "        \"Uinque_Char_Ratio\": len(set(domain))/max(1,len(domain)),\n",
        "        \"Max_Cons_Cluster\": max_cons_cluster(domain),\n",
        "        \"Dist_STD\": np.std(list(Counter(domain).values())),\n",
        "        \"Char_Gini\": char_gini(domain),\n",
        "        \"Char_Freq_Deviation\": char_freq_deviation(domain),\n",
        "        \"KL_Divergence\": kl_divergence(domain),\n",
        "        \"Compression_Ratio\": compress_ratio(domain),\n",
        "        \"Pronounceability\": pronouncability_score(domain),\n",
        "        \"Bigram_Score\": bigram_score(domain),\n",
        "        \"Trigram_Score\": trigram_score(domain),\n",
        "        \"Bigram_Likelihood\": bigram_score(domain)/max(1,len(domain)),\n",
        "        \"Markov_Chain_Likelihood\": markov_chain_likelihood(domain),\n",
        "        \"Ngram_LM_Perplexity\": ngram_lm_perplexity(domain),\n",
        "        \"Renyi_Entropy\": renyi_entropy(domain),\n",
        "\n",
        "        \"Keyboard_Distance_Score\": keyboard_distance_score(domain),\n",
        "        \"Kolmogorov_Complexity\": len(zlib.compress(domain.encode())),\n",
        "        \"Min_Levenshtein_To_Popular\": min_levenshtein_to_popular(domain),\n",
        "        \"Sliding_Word_Ratio\": sliding_dict_ratio(domain),\n",
        "        \"Normal_Char_Freq_Var\": normal_char_freq_variance(domain),\n",
        "        \"Consonant_Count\": consonant_count(domain),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #\"Digit_Count\": len(digits),\n",
        "        #\"Markov_Cross_Entropy\": shannon_entropy(domain) - markov_chain_likelihood(domain),\n",
        "        #\"Digit_Ratio\": len(digits)/max(1,len(domain)),\n",
        "        #\"Max_Consec_Digits\": max_consec_digits,\n",
        "        #\"Vowel_Count\": vowel_count(domain),\n",
        "\n",
        "\n",
        "        #\"Has_Hyphen\": has_hyphen,\n",
        "        #\"Subdomain_Depth\": domain.count(\".\"),\n",
        "        #\n",
        "        # === Statistical / Info-Theoretic Features ===\n",
        "        #\"Entropy\": shannon_entropy(domain),\n",
        "        #\"Normalized_Entropy\": normalized_entropy(domain),\n",
        "        #\"Vowel_Entropy\": shannon_entropy(\"\".join([c for c in domain if c in VOWELS])),\n",
        "        #\"Consonant_Entropy\": shannon_entropy(\"\".join([c for c in domain if c in CONSONANTS])),\n",
        "\n",
        "        # === Dictionary & Word Features ===\n",
        "        #\"Word_Match_Ratio\": dwc/max(1,len(domain.split(\".\"))),\n",
        "\n",
        "        #\"Dict_Word_Count\": dwc,\n",
        "        #\"Longest_Word_Len\": lwl,\n",
        "        #\"Longest_Word_Ratio\": lwr,\n",
        "        #\"Min_Levenshtein_Top\": min_levenshtein_to_popular(domain),\n",
        "        # === Pronounceability / Lexical Features ===\n",
        "\n",
        "        #\"Vowel_Consonant_Alt\": vowel_consonant_alt(domain),\n",
        "        #\"Lexical_Complexity\": shannon_entropy(domain)*len(set(domain))/max(1,len(domain)),\n",
        "        # === N-gram / Language Model ===\n",
        "\n",
        "        # === TLD / Popularity ===\n",
        "        #\"TLD_Common\": 1 if f\".{tld}\" in POPULAR_TLDS else 0,\n",
        "        #\"TLD_Bad_Score\": 1 if f\".{tld}\" in BAD_TLDS else 0,\n",
        "        #\"Popular_Domain\": 1 if domain in POPULAR_DOMAINS else 0,\n",
        "        #\"Alexa_popularity_bucket\": -1,  # placeholder\n",
        "        #\"TLD_Length\": len(tld),\n",
        "        #\"TLD_Rarity_Score\": 0 if f\".{tld}\" in POPULAR_TLDS else 1,\n",
        "        # === Structural / Pattern Features ===\n",
        "        #\"Repeat_Chars\": max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0),\n",
        "        #\"Max_Repeated_Char_Run\": max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0),\n",
        "        #\"Digit_Letter_Alt_Count\": sum((domain[i].isdigit() != domain[i+1].isdigit()) for i in range(len(domain)-1)),\n",
        "        #\"Palindromic_Substring_Ratio\": sum(domain[i:j]==domain[i:j][::-1] for i in range(len(domain)) for j in range(i+2,len(domain)+1))/max(1,len(domain)),\n",
        "        #\"First_Last_Char_Type\": int(domain[0].isalpha()) + int(domain[-1].isalpha()),\n",
        "        #\"Permutation_Entropy\": shannon_entropy(domain)/max(1,math.log2(len(domain))),\n",
        "        #\"Word_Boundary_Count\": domain.count(\"-\"),\n",
        "        #\"Syllable_Count\": sum(domain.count(v) for v in VOWELS),\n",
        "        #\"Hyphen_Placement_Score\": 1 if domain.startswith(\"-\") or domain.endswith(\"-\") else 0,\n",
        "\n",
        "        #\"RunLength_Entropy\": shannon_entropy(\"\".join([str(len(m.group())) for m in re.finditer(r'(.)\\1*', domain)])),\n",
        "\n",
        "        #\"Autocorrelation_Score\": autocorrelation_score(domain),\n",
        "        #\"Hurst_Exponent\": 0.5,  # placeholder\n",
        "        #\"Hyphen_Word_Match_Ratio\": hyphen_word_match_ratio(domain),\n",
        "\n",
        "    }\n",
        "    return feats\n",
        "\n",
        "\n",
        "\n",
        "def compute_features_for_dataset(df, domain_col=\"domain\"):\n",
        "    feature_rows = []\n",
        "    for domain in df[domain_col]:\n",
        "        feats = extract_features(domain.lower())\n",
        "        feature_rows.append(feats)\n",
        "    if feature_rows:\n",
        "      # Create DataFrame from list of dictionaries\n",
        "      feature_df = pd.DataFrame(feature_rows)\n",
        "      # Ensure columns match the keys from extract_features\n",
        "      feature_df = feature_df[list(feature_rows[0].keys())]\n",
        "      return feature_df\n",
        "    else:\n",
        "      return pd.DataFrame()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Training Phase\n",
        "# =========================\n",
        "def train_model(train_file, label_col=\"label\", model_type=\"xgboost\", save_model=\"dga_model.pkl\"):\n",
        "    # Load training dataset (already has features + labels)\n",
        "    df = pd.read_csv(train_file)\n",
        "\n",
        "    # Drop label + domain if exists\n",
        "    drop_cols = [label_col]\n",
        "    if \"domain\" in df.columns:\n",
        "        drop_cols.append(\"domain\")\n",
        "\n",
        "    X = df.drop(columns=drop_cols)\n",
        "    y = df[label_col]\n",
        "\n",
        "    # Ensure all features are numeric\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if model_type == \"xgboost\":\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "    else:\n",
        "        model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    print(\"Validation Accuracy:\", accuracy_score(y_val, preds))\n",
        "    print(classification_report(y_val, preds))\n",
        "\n",
        "    joblib.dump(model, save_model)\n",
        "    print(f\"✅ Model saved to {save_model}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Prediction Phase\n",
        "# =========================\n",
        "def predict_new(test_file, model_file=\"dga_model.pkl\", output_file=\"predictions_ndga.csv\"):\n",
        "    # Load test dataset\n",
        "    df_test = pd.read_csv(test_file)\n",
        "\n",
        "    # Detect which column to use for domains\n",
        "    if \"domain\" in df_test.columns:\n",
        "        domain_col = \"domain\"\n",
        "    else:\n",
        "        # Assume the first column holds the domain strings\n",
        "        domain_col = df_test.columns[0]\n",
        "\n",
        "    # Compute features\n",
        "    X_test = compute_features_for_dataset(df_test, domain_col=domain_col)\n",
        "\n",
        "    # Ensure numeric dtype\n",
        "    X_test = X_test.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # Load trained model\n",
        "    model = joblib.load(model_file)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Attach predictions alongside original domains\n",
        "    df_out = df_test.copy()\n",
        "    df_out[\"Prediction\"] = preds\n",
        "\n",
        "    df_out.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Predictions saved to {output_file}\")\n",
        "    return df_out\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "# Train the model\n",
        "model = train_model(\"combined.csv\", label_col=\"label\", model_type=\"xgboost\")\n",
        "\n",
        "# Predict on new domains\n",
        "results = predict_new(\"dataset_ndga.csv\", model_file=\"dga_model.pkl\")\n",
        "print(results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGHvE31og-V4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "pd.download(\"combined.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM0wXPtJ7B23"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Min_Levenshtein_to_Popular\"\n",
        "def count_zero_one(df, column_name):\n",
        "    \"\"\"\n",
        "    Count how many entries are 0 or 1 in a specific column.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input dataset\n",
        "    column_name : str\n",
        "        Column to check\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : counts of 0 and 1\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_name}' not found in dataset\")\n",
        "\n",
        "    counts = {\n",
        "        \"count_0\": (df[column_name] == 0).sum(),\n",
        "        \"count_1\": (df[column_name] == 1).sum()\n",
        "    }\n",
        "    return counts\n",
        "\n",
        "\n",
        "# ==== Example Usage ====\n",
        "df = pd.read_csv(\"predictions_dga.csv\")\n",
        "\n",
        "# Replace \"Label\" with your column name\n",
        "result = count_zero_one(df, \"Prediction\")\n",
        "\n",
        "print(f\"Number of 0s: {result['count_0']}\")\n",
        "print(f\"Number of 1s: {result['count_1']}\")\n",
        "\n",
        "\n",
        "\n",
        "##DGA-86%\n",
        "## Benign 87%\n",
        "\n",
        "##DGA-89%\n",
        "## Benign 86%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYgbDje6iYx6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import joblib\n",
        "from collections import Counter\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from difflib import SequenceMatcher # Import SequenceMatcher\n",
        "\n",
        "# =========================\n",
        "# Feature Extraction Utils\n",
        "# =========================\n",
        "\n",
        "try:\n",
        "    from nltk.corpus import words\n",
        "    from nltk import download\n",
        "    download('words')\n",
        "    ENGLISH_WORDS = set(w.lower() for w in words.words())\n",
        "except:\n",
        "    ENGLISH_WORDS = {\"test\", \"shop\", \"mail\", \"home\", \"secure\", \"login\"}  # fallback small dict\n",
        "\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(\"bcdfghjklmnpqrstvwxyz\")\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "\n",
        "# Load top domains (free list like Tranco or Cisco Umbrella top domains)\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        popular_domains = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    popular_domains = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]  # fallback demo list\n",
        "\n",
        "\n",
        "def shannon_entropy(s):\n",
        "    if not s:\n",
        "        return 0\n",
        "    probs = [s.count(c) / len(s) for c in set(s)]\n",
        "    return -sum(p * math.log2(p) for p in probs)\n",
        "\n",
        "def char_gini(domain: str) -> float:\n",
        "    \"\"\"Compute Gini index of character distribution in the domain\"\"\"\n",
        "    if not domain:\n",
        "        return 0.0\n",
        "    counts = np.array([domain.count(c) for c in set(domain)])\n",
        "    probs = counts / counts.sum()\n",
        "    return 1.0 - np.sum(probs ** 2)\n",
        "\n",
        "def get_tld(domain: str) -> str:\n",
        "    \"\"\"Extracts the top-level domain (TLD) from a domain string.\"\"\"\n",
        "    parts = domain.split(\".\")\n",
        "    if len(parts) > 1:\n",
        "        return \".\" + parts[-1]  # include dot for matching with POPULAR_TLDS/BAD_TLDS\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def digit_count(domain):\n",
        "    return sum(c.isdigit() for c in domain)\n",
        "\n",
        "def vowel_count(domain):\n",
        "    return sum(c in VOWELS for c in domain)\n",
        "\n",
        "def consonant_count(domain):\n",
        "    return sum(c in CONSONANTS for c in domain)\n",
        "\n",
        "def unique_chars(domain):\n",
        "    return len(set(domain))\n",
        "\n",
        "def has_hyphen(domain):\n",
        "    return 1 if \"-\" in domain else 0\n",
        "\n",
        "def subdomain_depth(domain):\n",
        "    return domain.count(\".\")  # depth based on dots\n",
        "\n",
        "def max_consec_digits(domain):\n",
        "    return max((len(m.group()) for m in re.finditer(r\"\\d+\", domain)), default=0)\n",
        "\n",
        "def max_cons_cluster(domain):\n",
        "    return max((len(m.group()) for m in re.finditer(r\"[bcdfghjklmnpqrstvwxyz]+\", domain)), default=0)\n",
        "\n",
        "def hyphen_word_match_ratio(domain: str) -> float:\n",
        "    \"\"\"Ratio of hyphen-separated parts that are valid dictionary words.\"\"\"\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts:\n",
        "        return 0.0\n",
        "    dict_matches = sum(1 for p in parts if p in ENGLISH_WORDS)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "# === Extra Feature Functions ===\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    \"\"\"Rényi entropy of order alpha (default α=2).\"\"\"\n",
        "    if not s:\n",
        "        return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs * np.log2(probs))  # Shannon\n",
        "    return 1 / (1 - alpha) * np.log2(np.sum(probs ** alpha))\n",
        "\n",
        "# Load top domains (free list like Tranco or Cisco Umbrella top domains)\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        popular_domains = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    popular_domains = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]  # fallback demo list\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    \"\"\"Compute minimum normalized Levenshtein distance to topN popular domains.\"\"\"\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in popular_domains[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio  # 0 = identical, 1 = very different\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "# Keyboard adjacency mapping\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q': \"was\", 'w': \"qase\", 'e': \"wsdr\", 'r': \"edft\", 't': \"rfgy\",\n",
        "    'y': \"tghu\", 'u': \"yhj\", 'i': \"ujk\", 'o': \"ikl\", 'p': \"ol\",\n",
        "    'a': \"qwsz\", 's': \"qwedxza\", 'd': \"erfcxs\", 'f': \"rtgvcd\", 'g': \"tyhbvf\",\n",
        "    'h': \"yujnbg\", 'j': \"uikmnh\", 'k': \"iolmj\", 'l': \"opk\",\n",
        "    'z': \"asx\", 'x': \"zsdc\", 'c': \"xdfv\", 'v': \"cfgb\", 'b': \"vghn\",\n",
        "    'n': \"bhjm\", 'm': \"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    \"\"\"Average keyboard adjacency match score between consecutive characters.\"\"\"\n",
        "    domain = re.sub(r'[^a-z]', '', domain.lower())\n",
        "    if len(domain) < 2:\n",
        "        return 0\n",
        "    score = 0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i], \"\"):\n",
        "            score += 1\n",
        "    return score / (len(domain)-1)\n",
        "\n",
        "\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str):\n",
        "        domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    name, _, tld = domain.rpartition(\".\")\n",
        "    if not name:\n",
        "        name = domain\n",
        "\n",
        "    feats = {\n",
        "         #\"Min_Levenshtein_to_Popular\": min_levenshtein_to_popular(domain),\n",
        "         \"Keyboard_Distance_Score\": keyboard_distance_score(domain)\n",
        "    }\n",
        "    return feats\n",
        "\n",
        "\n",
        "def compute_features_for_dataset(df, domain_col=\"domain\"):\n",
        "    feature_rows = []\n",
        "    for domain in df[domain_col]:\n",
        "        feats = extract_features(domain.lower())\n",
        "        feature_rows.append(feats)\n",
        "    if feature_rows:\n",
        "      # Create DataFrame from list of dictionaries\n",
        "      feature_df = pd.DataFrame(feature_rows)\n",
        "      # Ensure columns match the keys from extract_features\n",
        "      feature_df = feature_df[list(feature_rows[0].keys())]\n",
        "      return feature_df\n",
        "    else:\n",
        "      return pd.DataFrame()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Training Phase\n",
        "# =========================\n",
        "def train_model(train_file, label_col=\"label\", model_type=\"xgboost\", save_model=\"dga_model.pkl\"):\n",
        "    # Load training dataset (already has features + labels)\n",
        "    df = pd.read_csv(train_file)\n",
        "\n",
        "    # Drop label + domain if exists\n",
        "    drop_cols = [label_col]\n",
        "    if \"domain\" in df.columns:\n",
        "        drop_cols.append(\"domain\")\n",
        "\n",
        "    X = df.drop(columns=drop_cols)\n",
        "    y = df[label_col]\n",
        "\n",
        "    # Ensure all features are numeric\n",
        "    X = X.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if model_type == \"xgboost\":\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "    else:\n",
        "        model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    print(\"Validation Accuracy:\", accuracy_score(y_val, preds))\n",
        "    print(classification_report(y_val, preds))\n",
        "\n",
        "    joblib.dump(model, save_model)\n",
        "    print(f\"✅ Model saved to {save_model}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Prediction Phase\n",
        "# =========================\n",
        "def predict_new(test_file, model_file=\"dga_model.pkl\", output_file=\"predictions_ndga.csv\"):\n",
        "    # Load test dataset\n",
        "    df_test = pd.read_csv(test_file)\n",
        "\n",
        "    # Detect which column to use for domains\n",
        "    if \"domain\" in df_test.columns:\n",
        "        domain_col = \"domain\"\n",
        "    else:\n",
        "        # Assume the first column holds the domain strings\n",
        "        domain_col = df_test.columns[0]\n",
        "\n",
        "    # Compute features\n",
        "    X_test = compute_features_for_dataset(df_test, domain_col=domain_col)\n",
        "\n",
        "    # Ensure numeric dtype\n",
        "    X_test = X_test.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # Load trained model\n",
        "    model = joblib.load(model_file)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Attach predictions alongside original domains\n",
        "    df_out = df_test.copy()\n",
        "    df_out[\"Prediction\"] = preds\n",
        "\n",
        "    df_out.to_csv(output_file, index=False)\n",
        "    print(f\"✅ Predictions saved to {output_file}\")\n",
        "    return df_out\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "# Train the model\n",
        "model = train_model(\"combined.csv\", label_col=\"label\", model_type=\"xgboost\")\n",
        "\n",
        "# Predict on new domains\n",
        "results = predict_new(\"dataset_ndga.csv\", model_file=\"dga_model.pkl\")\n",
        "print(results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5NxQ-jqib2K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def count_zero_one(df, column_name):\n",
        "    \"\"\"\n",
        "    Count how many entries are 0 or 1 in a specific column.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Input dataset\n",
        "    column_name : str\n",
        "        Column to check\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : counts of 0 and 1\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_name}' not found in dataset\")\n",
        "\n",
        "    counts = {\n",
        "        \"count_0\": (df[column_name] == 0).sum(),\n",
        "        \"count_1\": (df[column_name] == 1).sum()\n",
        "    }\n",
        "    return counts\n",
        "\n",
        "\n",
        "# ==== Example Usage ====\n",
        "df = pd.read_csv(\"predictions_ndga.csv\")\n",
        "\n",
        "# Replace \"Label\" with your column name\n",
        "result = count_zero_one(df, \"Prediction\")\n",
        "\n",
        "print(f\"Number of 0s: {result['count_0']}\")\n",
        "print(f\"Number of 1s: {result['count_1']}\")\n",
        " ##dga 79\n",
        " ## 68\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsyFTXJBEh6y"
      },
      "outputs": [],
      "source": [
        " # 0 ---> 84/75\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCt-QiLe2zWj"
      },
      "outputs": [],
      "source": [
        "#all dga 90%\n",
        "#benign 86%\n",
        "#-2:compression ratio\n",
        "#:Bigram score\n",
        "# dga 89\n",
        "#BENIGN: 86"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epT1qccnSetD"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# DGA Feature Extraction + Model Training Pipeline\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import zlib\n",
        "import string\n",
        "from collections import Counter\n",
        "from difflib import SequenceMatcher\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.corpus import words\n",
        "from nltk import download\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# -------------------------\n",
        "# Download English words\n",
        "# -------------------------\n",
        "try:\n",
        "    download('words')\n",
        "    ENGLISH_WORDS = set(w.lower() for w in words.words())\n",
        "except:\n",
        "    ENGLISH_WORDS = {\"test\",\"shop\",\"login\",\"home\",\"mail\",\"secure\"}  # fallback\n",
        "\n",
        "# -------------------------\n",
        "# Constants\n",
        "# -------------------------\n",
        "VOWELS = set(\"aeiou\")\n",
        "CONSONANTS = set(string.ascii_lowercase) - VOWELS\n",
        "POPULAR_TLDS = {\".com\", \".org\", \".net\", \".info\", \".edu\", \".gov\"}\n",
        "BAD_TLDS = {\".xyz\", \".top\", \".club\", \".work\", \".click\"}\n",
        "BENIGN_DIST = np.ones(26)/26  # uniform for KL divergence\n",
        "\n",
        "# -------------------------\n",
        "# Load top domains\n",
        "# -------------------------\n",
        "try:\n",
        "    with open(\"top1k_domains.txt\") as f:\n",
        "        POPULAR_DOMAINS = [line.strip().lower() for line in f.readlines()]\n",
        "except FileNotFoundError:\n",
        "    POPULAR_DOMAINS = [\"google.com\",\"facebook.com\",\"youtube.com\",\"amazon.com\",\"wikipedia.org\"]\n",
        "\n",
        "# -------------------------\n",
        "# Feature Functions\n",
        "# -------------------------\n",
        "def shannon_entropy(s):\n",
        "    if not s: return 0\n",
        "    p, _ = np.histogram(list(s), bins=range(257), density=True)\n",
        "    p = p[p>0]\n",
        "    return -np.sum(p*np.log2(p))\n",
        "\n",
        "def normalized_entropy(s):\n",
        "    if not s: return 0\n",
        "    return shannon_entropy(s)/math.log2(len(set(s))+1)\n",
        "\n",
        "def compress_ratio(s):\n",
        "    if not s: return 0\n",
        "    return len(zlib.compress(s.encode()))/max(1,len(s))\n",
        "\n",
        "def renyi_entropy(s, alpha=2):\n",
        "    if not s: return 0\n",
        "    counts = Counter(s)\n",
        "    probs = np.array(list(counts.values())) / len(s)\n",
        "    if alpha == 1:\n",
        "        return -np.sum(probs*np.log2(probs))\n",
        "    return 1/(1-alpha) * np.log2(np.sum(probs**alpha))\n",
        "\n",
        "def min_levenshtein_to_popular(domain, topN=500):\n",
        "    domain = domain.lower()\n",
        "    min_dist = 1.0\n",
        "    for pd in POPULAR_DOMAINS[:topN]:\n",
        "        ratio = SequenceMatcher(None, domain, pd).ratio()\n",
        "        dist = 1 - ratio\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "    return min_dist\n",
        "\n",
        "KEYBOARD_NEIGHBORS = {\n",
        "    'q':\"was\",'w':\"qase\",'e':\"wsdr\",'r':\"edft\",'t':\"rfgy\",\n",
        "    'y':\"tghu\",'u':\"yhj\",'i':\"ujk\",'o':\"ikl\",'p':\"ol\",\n",
        "    'a':\"qwsz\",'s':\"qwedxza\",'d':\"erfcxs\",'f':\"rtgvcd\",'g':\"tyhbvf\",\n",
        "    'h':\"yujnbg\",'j':\"uikmnh\",'k':\"iolmj\",'l':\"opk\",\n",
        "    'z':\"asx\",'x':\"zsdc\",'c':\"xdfv\",'v':\"cfgb\",'b':\"vghn\",\n",
        "    'n':\"bhjm\",'m':\"njk\"\n",
        "}\n",
        "\n",
        "def keyboard_distance_score(domain):\n",
        "    domain = re.sub(r'[^a-z]','',domain.lower())\n",
        "    if len(domain)<2: return 0\n",
        "    score=0\n",
        "    for i in range(len(domain)-1):\n",
        "        if domain[i+1] in KEYBOARD_NEIGHBORS.get(domain[i],\"\"):\n",
        "            score+=1\n",
        "    return score/(len(domain)-1)\n",
        "\n",
        "def dict_word_features(domain):\n",
        "    matches = [w for w in ENGLISH_WORDS if w in domain]\n",
        "    longest = max((len(w) for w in matches), default=0)\n",
        "    return len(matches), longest, longest/max(1,len(domain))\n",
        "\n",
        "def sliding_dict_ratio(domain, window=4):\n",
        "    n=len(domain)\n",
        "    if n<window: return 0\n",
        "    matches=0\n",
        "    for i in range(n-window+1):\n",
        "        if domain[i:i+window] in ENGLISH_WORDS:\n",
        "            matches+=1\n",
        "    return matches/(n-window+1)\n",
        "\n",
        "def vowel_consonant_alt(domain):\n",
        "    domain=re.sub(r'[^a-z]','',domain.lower())\n",
        "    count=0\n",
        "    for i in range(1,len(domain)):\n",
        "        if (domain[i] in VOWELS and domain[i-1] in CONSONANTS) or (domain[i] in CONSONANTS and domain[i-1] in VOWELS):\n",
        "            count+=1\n",
        "    return count\n",
        "\n",
        "def char_gini(s):\n",
        "    counts=Counter(s)\n",
        "    N=sum(counts.values())\n",
        "    if N==0: return 0\n",
        "    return 1 - sum((c/N)**2 for c in counts.values())\n",
        "\n",
        "def kl_divergence(s):\n",
        "    counts=Counter([c for c in s if c.isalpha()])\n",
        "    N=sum(counts.values())\n",
        "    if N==0: return 0\n",
        "    dist=np.array([counts.get(chr(97+i),0)/N for i in range(26)])\n",
        "    return entropy(dist, BENIGN_DIST)\n",
        "\n",
        "def markov_chain_likelihood(domain):\n",
        "    if len(domain)<2: return 0\n",
        "    transitions={}\n",
        "    for i in range(len(domain)-1):\n",
        "        pair=(domain[i],domain[i+1])\n",
        "        transitions[pair]=transitions.get(pair,0)+1\n",
        "    total=sum(transitions.values())\n",
        "    return sum(math.log((c/total)+1e-6) for c in transitions.values())\n",
        "\n",
        "def autocorrelation_score(domain):\n",
        "    if len(domain)<2: return 0\n",
        "    vals=[ord(c) for c in domain]\n",
        "    mean=np.mean(vals)\n",
        "    var=np.var(vals)\n",
        "    return sum((vals[i]-mean)*(vals[i+1]-mean) for i in range(len(vals)-1))/(var*(len(vals)-1)+1e-6)\n",
        "\n",
        "def hyphen_word_match_ratio(domain):\n",
        "    parts = domain.split(\"-\")\n",
        "    if not parts: return 0\n",
        "    dict_matches = sum(1 for p in parts if p in ENGLISH_WORDS)\n",
        "    return dict_matches / len(parts)\n",
        "\n",
        "def max_cons_cluster(domain):\n",
        "    return max((len(m.group()) for m in re.finditer(r\"[bcdfghjklmnpqrstvwxyz]+\", domain.lower())), default=0)\n",
        "\n",
        "def consonant_count(domain):\n",
        "    return sum(c in CONSONANTS for c in domain.lower())\n",
        "\n",
        "def vowel_count(domain):\n",
        "    return sum(c in VOWELS for c in domain.lower())\n",
        "\n",
        "def pronouncability_score(domain):\n",
        "    return vowel_count(domain)/ (consonant_count(domain)+1)\n",
        "\n",
        "def bigram_score(domain):\n",
        "    return sum(1 for i in range(len(domain)-1) if domain[i].isalpha() and domain[i+1].isalpha())\n",
        "\n",
        "def trigram_score(domain):\n",
        "    return sum(1 for i in range(len(domain)-2) if domain[i].isalpha() and domain[i+2].isalpha())\n",
        "\n",
        "def ngram_lm_perplexity(domain):\n",
        "    likelihood = markov_chain_likelihood(domain)\n",
        "    if len(domain)==0:\n",
        "        return 0\n",
        "    return math.exp(-likelihood / len(domain))\n",
        "\n",
        "def char_freq_deviation(domain):\n",
        "    counts = list(Counter(domain).values())\n",
        "    return np.std(counts) if counts else 0\n",
        "\n",
        "def normal_char_freq_variance(domain):\n",
        "    counts = list(Counter(domain).values())\n",
        "    return (np.std(counts)/len(domain)) if domain else 0\n",
        "\n",
        "# -------------------------\n",
        "# Main feature extractor\n",
        "\n",
        "def extract_features(domain):\n",
        "    if not isinstance(domain, str): domain = str(domain)\n",
        "    domain = domain.lower()\n",
        "    dwc, lwl, lwr = dict_word_features(domain)\n",
        "    tld = domain.split(\".\")[-1] if \".\" in domain else \"\"\n",
        "\n",
        "    digits = [c for c in domain if c.isdigit()]\n",
        "    max_consec_digits = max((len(m.group()) for m in re.finditer(r'\\d+', domain)), default=0)\n",
        "    has_hyphen = 1 if \"-\" in domain else 0\n",
        "\n",
        "    feats = {\n",
        "        # === Core Structural Features ===\n",
        "        \"Length\": len(domain),\n",
        "        \"Digit_Count\": len(digits),\n",
        "        \"Digit_Ratio\": len(digits)/max(1,len(domain)),\n",
        "        \"Max_Consec_Digits\": max_consec_digits,\n",
        "        \"Vowel_Count\": vowel_count(domain),\n",
        "        \"Consonant_Count\": consonant_count(domain),\n",
        "        \"Unique_Chars\": len(set(domain)),\n",
        "        \"Has_Hyphen\": has_hyphen,\n",
        "        \"Subdomain_Depth\": domain.count(\".\"),\n",
        "        \"Max_Cons_Cluster\": max_cons_cluster(domain),\n",
        "        # === Statistical / Info-Theoretic Features ===\n",
        "        \"Entropy\": shannon_entropy(domain),\n",
        "        \"Normalized_Entropy\": normalized_entropy(domain),\n",
        "        \"Vowel_Entropy\": shannon_entropy(\"\".join([c for c in domain if c in VOWELS])),\n",
        "        \"Consonant_Entropy\": shannon_entropy(\"\".join([c for c in domain if c in CONSONANTS])),\n",
        "        \"Dist_STD\": np.std(list(Counter(domain).values())),\n",
        "        \"Char_Gini\": char_gini(domain),\n",
        "        \"Char_Freq_Deviation\": char_freq_deviation(domain),\n",
        "        \"KL_Divergence\": kl_divergence(domain),\n",
        "        \"Compression_Ratio\": compress_ratio(domain),\n",
        "        # === Dictionary & Word Features ===\n",
        "        \"Word_Match_Ratio\": dwc/max(1,len(domain.split(\".\"))),\n",
        "        \"Sliding_Word_Ratio\": sliding_dict_ratio(domain),\n",
        "        \"Dict_Word_Count\": dwc,\n",
        "        \"Longest_Word_Len\": lwl,\n",
        "        \"Longest_Word_Ratio\": lwr,\n",
        "        \"Min_Levenshtein_Top\": min_levenshtein_to_popular(domain),\n",
        "        # === Pronounceability / Lexical Features ===\n",
        "        \"Pronounceability\": pronouncability_score(domain),\n",
        "        \"Vowel_Consonant_Alt\": vowel_consonant_alt(domain),\n",
        "        \"Lexical_Complexity\": shannon_entropy(domain)*len(set(domain))/max(1,len(domain)),\n",
        "        # === N-gram / Language Model ===\n",
        "        \"Bigram_Score\": bigram_score(domain),\n",
        "        \"Trigram_Score\": trigram_score(domain),\n",
        "        \"Bigram_Likelihood\": bigram_score(domain)/max(1,len(domain)),\n",
        "        \"Char_Markov_Likelihood\": markov_chain_likelihood(domain),\n",
        "        \"Ngram_LM_Perplexity\": ngram_lm_perplexity(domain),\n",
        "        # === TLD / Popularity ===\n",
        "        \"TLD_Common\": 1 if f\".{tld}\" in POPULAR_TLDS else 0,\n",
        "        \"TLD_Bad_Score\": 1 if f\".{tld}\" in BAD_TLDS else 0,\n",
        "        \"Popular_Domain\": 1 if domain in POPULAR_DOMAINS else 0,\n",
        "        \"Alexa_popularity_bucket\": -1,  # placeholder\n",
        "        \"TLD_Length\": len(tld),\n",
        "        \"TLD_Rarity_Score\": 0 if f\".{tld}\" in POPULAR_TLDS else 1,\n",
        "        # === Structural / Pattern Features ===\n",
        "        \"Repeat_Chars\": max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0),\n",
        "        \"Max_Repeated_Char_Run\": max((len(m.group()) for m in re.finditer(r'(.)\\1+', domain)), default=0),\n",
        "        \"Digit_Letter_Alt_Count\": sum((domain[i].isdigit() != domain[i+1].isdigit()) for i in range(len(domain)-1)),\n",
        "        \"Palindromic_Substring_Ratio\": sum(domain[i:j]==domain[i:j][::-1] for i in range(len(domain)) for j in range(i+2,len(domain)+1))/max(1,len(domain)),\n",
        "        \"First_Last_Char_Type\": int(domain[0].isalpha()) + int(domain[-1].isalpha()),\n",
        "        \"Permutation_Entropy\": shannon_entropy(domain)/max(1,math.log2(len(domain))),\n",
        "        \"Word_Boundary_Count\": domain.count(\"-\"),\n",
        "        \"Syllable_Count\": sum(domain.count(v) for v in VOWELS),\n",
        "        \"Hyphen_Placement_Score\": 1 if domain.startswith(\"-\") or domain.endswith(\"-\") else 0,\n",
        "        \"Renyi_Entropy\": renyi_entropy(domain),\n",
        "        \"Markov_Cross_Entropy\": shannon_entropy(domain) - markov_chain_likelihood(domain),\n",
        "        \"RunLength_Entropy\": shannon_entropy(\"\".join([str(len(m.group())) for m in re.finditer(r'(.)\\1*', domain)])),\n",
        "        \"Normalized_Char_Freq_Var\": normal_char_freq_variance(domain),\n",
        "        \"Autocorrelation_Score\": autocorrelation_score(domain),\n",
        "        \"Hurst_Exponent\": 0.5,  # placeholder\n",
        "        \"Hyphen_Word_Match_Ratio\": hyphen_word_match_ratio(domain),\n",
        "        \"Keyboard_Distance_Score\": keyboard_distance_score(domain)\n",
        "    }\n",
        "    return feats\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Dataset Feature Computation\n",
        "# -------------------------\n",
        "def compute_features_for_dataset(df, domain_col=\"domain\"):\n",
        "    return pd.DataFrame([extract_features(d) for d in df[domain_col]])\n",
        "\n",
        "# -------------------------\n",
        "# Train Model\n",
        "# -------------------------\n",
        "def train_model(train_file, label_col=\"label\", model_type=\"xgboost\", save_model=\"dga_model.pkl\"):\n",
        "    df = pd.read_csv(train_file)\n",
        "    X = compute_features_for_dataset(df)\n",
        "    y = df[label_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    if model_type==\"xgboost\":\n",
        "        model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\n",
        "    else:\n",
        "        model = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    joblib.dump(model, save_model)\n",
        "    print(f\"✅ Model saved to {save_model}\")\n",
        "    return model\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}